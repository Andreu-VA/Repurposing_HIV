{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train= pd.read_csv(\"../data/processed/train_w_desc.csv\")\n",
    "df_test= pd.read_csv(\"../data/processed/test_w_desc.csv\")\n",
    "train_rdkfp= pd.read_csv(\"../data/processed/train_rdkfp.csv\")\n",
    "test_rdkfp= pd.read_csv(\"../data/processed/test_rdkfp.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Drug_ID</th>\n",
       "      <th>Drug</th>\n",
       "      <th>Y</th>\n",
       "      <th>mol</th>\n",
       "      <th>tpsa</th>\n",
       "      <th>mol_w</th>\n",
       "      <th>qed</th>\n",
       "      <th>HBA</th>\n",
       "      <th>HBD</th>\n",
       "      <th>logP</th>\n",
       "      <th>MR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Drug 0</td>\n",
       "      <td>CCC1=[O+][Cu-3]2([O+]=C(CC)C1)[O+]=C(CC)CC(CC)...</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;rdkit.Chem.rdchem.Mol object at 0x00000201534...</td>\n",
       "      <td>45.20</td>\n",
       "      <td>319.096508</td>\n",
       "      <td>0.434358</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.6669</td>\n",
       "      <td>70.4260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Drug 2</td>\n",
       "      <td>CC(=O)N1c2ccccc2Sc2c1ccc1ccccc21</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;rdkit.Chem.rdchem.Mol object at 0x00000201534...</td>\n",
       "      <td>20.31</td>\n",
       "      <td>291.071785</td>\n",
       "      <td>0.581359</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4.9890</td>\n",
       "      <td>87.3330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Drug 5</td>\n",
       "      <td>CCOP(=O)(Nc1cccc(Cl)c1)OCC</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;rdkit.Chem.rdchem.Mol object at 0x00000201531...</td>\n",
       "      <td>47.56</td>\n",
       "      <td>263.047808</td>\n",
       "      <td>0.790087</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3.9330</td>\n",
       "      <td>65.9332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Drug 6</td>\n",
       "      <td>O=C(O)c1ccccc1O</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;rdkit.Chem.rdchem.Mol object at 0x00000201531...</td>\n",
       "      <td>57.53</td>\n",
       "      <td>138.031694</td>\n",
       "      <td>0.610259</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0904</td>\n",
       "      <td>35.0661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Drug 8</td>\n",
       "      <td>O=[N+]([O-])c1ccc(SSc2ccc([N+](=O)[O-])cc2[N+]...</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;rdkit.Chem.rdchem.Mol object at 0x00000201531...</td>\n",
       "      <td>172.56</td>\n",
       "      <td>397.962705</td>\n",
       "      <td>0.374691</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>4.1188</td>\n",
       "      <td>91.2156</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Drug_ID                                               Drug  Y  \\\n",
       "0  Drug 0  CCC1=[O+][Cu-3]2([O+]=C(CC)C1)[O+]=C(CC)CC(CC)...  0   \n",
       "1  Drug 2                   CC(=O)N1c2ccccc2Sc2c1ccc1ccccc21  0   \n",
       "2  Drug 5                         CCOP(=O)(Nc1cccc(Cl)c1)OCC  0   \n",
       "3  Drug 6                                    O=C(O)c1ccccc1O  0   \n",
       "4  Drug 8  O=[N+]([O-])c1ccc(SSc2ccc([N+](=O)[O-])cc2[N+]...  0   \n",
       "\n",
       "                                                 mol    tpsa       mol_w  \\\n",
       "0  <rdkit.Chem.rdchem.Mol object at 0x00000201534...   45.20  319.096508   \n",
       "1  <rdkit.Chem.rdchem.Mol object at 0x00000201534...   20.31  291.071785   \n",
       "2  <rdkit.Chem.rdchem.Mol object at 0x00000201531...   47.56  263.047808   \n",
       "3  <rdkit.Chem.rdchem.Mol object at 0x00000201531...   57.53  138.031694   \n",
       "4  <rdkit.Chem.rdchem.Mol object at 0x00000201531...  172.56  397.962705   \n",
       "\n",
       "        qed  HBA  HBD    logP       MR  \n",
       "0  0.434358    0    0  2.6669  70.4260  \n",
       "1  0.581359    2    0  4.9890  87.3330  \n",
       "2  0.790087    3    1  3.9330  65.9332  \n",
       "3  0.610259    3    2  1.0904  35.0661  \n",
       "4  0.374691   10    0  4.1188  91.2156  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train= df_train[[\"tpsa\",\"mol_w\",\"qed\",\"HBA\",\"HBD\",\"logP\",\"MR\"]]\n",
    "y_train= df_train[\"Y\"]\n",
    "X_test= df_test[[\"tpsa\",\"mol_w\",\"qed\",\"HBA\",\"HBD\",\"logP\",\"MR\"]]\n",
    "y_test= df_test[\"Y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_train= X_train.join(train_rdkfp)\n",
    "joined_test= X_test.join(test_rdkfp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tpsa</th>\n",
       "      <th>mol_w</th>\n",
       "      <th>qed</th>\n",
       "      <th>HBA</th>\n",
       "      <th>HBD</th>\n",
       "      <th>logP</th>\n",
       "      <th>MR</th>\n",
       "      <th>Bit_0</th>\n",
       "      <th>Bit_1</th>\n",
       "      <th>Bit_2</th>\n",
       "      <th>...</th>\n",
       "      <th>Bit_2038</th>\n",
       "      <th>Bit_2039</th>\n",
       "      <th>Bit_2040</th>\n",
       "      <th>Bit_2041</th>\n",
       "      <th>Bit_2042</th>\n",
       "      <th>Bit_2043</th>\n",
       "      <th>Bit_2044</th>\n",
       "      <th>Bit_2045</th>\n",
       "      <th>Bit_2046</th>\n",
       "      <th>Bit_2047</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45.20</td>\n",
       "      <td>319.096508</td>\n",
       "      <td>0.434358</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.6669</td>\n",
       "      <td>70.4260</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.31</td>\n",
       "      <td>291.071785</td>\n",
       "      <td>0.581359</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4.9890</td>\n",
       "      <td>87.3330</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47.56</td>\n",
       "      <td>263.047808</td>\n",
       "      <td>0.790087</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3.9330</td>\n",
       "      <td>65.9332</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>57.53</td>\n",
       "      <td>138.031694</td>\n",
       "      <td>0.610259</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0904</td>\n",
       "      <td>35.0661</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>172.56</td>\n",
       "      <td>397.962705</td>\n",
       "      <td>0.374691</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>4.1188</td>\n",
       "      <td>91.2156</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2055 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     tpsa       mol_w       qed  HBA  HBD    logP       MR  Bit_0  Bit_1  \\\n",
       "0   45.20  319.096508  0.434358    0    0  2.6669  70.4260      0      0   \n",
       "1   20.31  291.071785  0.581359    2    0  4.9890  87.3330      0      1   \n",
       "2   47.56  263.047808  0.790087    3    1  3.9330  65.9332      0      1   \n",
       "3   57.53  138.031694  0.610259    3    2  1.0904  35.0661      0      0   \n",
       "4  172.56  397.962705  0.374691   10    0  4.1188  91.2156      0      0   \n",
       "\n",
       "   Bit_2  ...  Bit_2038  Bit_2039  Bit_2040  Bit_2041  Bit_2042  Bit_2043  \\\n",
       "0      0  ...         0         0         0         0         1         0   \n",
       "1      0  ...         1         0         1         1         0         0   \n",
       "2      1  ...         1         1         1         0         0         1   \n",
       "3      1  ...         0         1         0         0         0         1   \n",
       "4      0  ...         0         0         0         1         0         1   \n",
       "\n",
       "   Bit_2044  Bit_2045  Bit_2046  Bit_2047  \n",
       "0         1         1         1         0  \n",
       "1         0         1         1         1  \n",
       "2         0         1         1         0  \n",
       "3         0         0         1         0  \n",
       "4         1         1         1         0  \n",
       "\n",
       "[5 rows x 2055 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler= MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled= scaler.fit_transform(joined_train)\n",
    "X_test_scaled= scaler.fit_transform(joined_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28789, 2055)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8225, 2055)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lg= LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Andreu\\anaconda3\\envs\\ml_project_env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lg.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lg_preds= lg.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmat_lg = confusion_matrix(y_test, lg_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7771,  157],\n",
       "       [ 203,   94]], dtype=int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmat_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.3164983164983165\n",
      "f1_score: 0.3430656934306569\n",
      "roc_auc: 0.6483475437183813\n"
     ]
    }
   ],
   "source": [
    "print(\"Recall:\", recall_score(y_test, lg_preds))\n",
    "print(\"f1_score:\", f1_score(y_test, lg_preds))\n",
    "print(\"roc_auc:\", roc_auc_score(y_test, lg_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The best recall with Logistic Regression using Morgan fingerprints was 0.26, \n",
    "# so there is a light improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_maccs= pd.read_csv(\"../data/processed/train_maccs.csv\")\n",
    "test_maccs= pd.read_csv(\"../data/processed/test_maccs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_train_maccs= X_train.join(train_maccs)\n",
    "joined_test_maccs= X_test.join(test_maccs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tpsa</th>\n",
       "      <th>mol_w</th>\n",
       "      <th>qed</th>\n",
       "      <th>HBA</th>\n",
       "      <th>HBD</th>\n",
       "      <th>logP</th>\n",
       "      <th>MR</th>\n",
       "      <th>Bit_0</th>\n",
       "      <th>Bit_1</th>\n",
       "      <th>Bit_2</th>\n",
       "      <th>...</th>\n",
       "      <th>Bit_157</th>\n",
       "      <th>Bit_158</th>\n",
       "      <th>Bit_159</th>\n",
       "      <th>Bit_160</th>\n",
       "      <th>Bit_161</th>\n",
       "      <th>Bit_162</th>\n",
       "      <th>Bit_163</th>\n",
       "      <th>Bit_164</th>\n",
       "      <th>Bit_165</th>\n",
       "      <th>Bit_166</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45.20</td>\n",
       "      <td>319.096508</td>\n",
       "      <td>0.434358</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.6669</td>\n",
       "      <td>70.4260</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.31</td>\n",
       "      <td>291.071785</td>\n",
       "      <td>0.581359</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4.9890</td>\n",
       "      <td>87.3330</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47.56</td>\n",
       "      <td>263.047808</td>\n",
       "      <td>0.790087</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3.9330</td>\n",
       "      <td>65.9332</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>57.53</td>\n",
       "      <td>138.031694</td>\n",
       "      <td>0.610259</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0904</td>\n",
       "      <td>35.0661</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>172.56</td>\n",
       "      <td>397.962705</td>\n",
       "      <td>0.374691</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>4.1188</td>\n",
       "      <td>91.2156</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 174 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     tpsa       mol_w       qed  HBA  HBD    logP       MR  Bit_0  Bit_1  \\\n",
       "0   45.20  319.096508  0.434358    0    0  2.6669  70.4260      0      0   \n",
       "1   20.31  291.071785  0.581359    2    0  4.9890  87.3330      0      0   \n",
       "2   47.56  263.047808  0.790087    3    1  3.9330  65.9332      0      0   \n",
       "3   57.53  138.031694  0.610259    3    2  1.0904  35.0661      0      0   \n",
       "4  172.56  397.962705  0.374691   10    0  4.1188  91.2156      0      0   \n",
       "\n",
       "   Bit_2  ...  Bit_157  Bit_158  Bit_159  Bit_160  Bit_161  Bit_162  Bit_163  \\\n",
       "0      0  ...        0        0        1        1        0        0        1   \n",
       "1      0  ...        0        1        0        1        1        1        1   \n",
       "2      0  ...        1        1        1        1        1        1        1   \n",
       "3      0  ...        1        0        1        0        0        1        1   \n",
       "4      0  ...        0        1        1        0        1        1        1   \n",
       "\n",
       "   Bit_164  Bit_165  Bit_166  \n",
       "0        1        1        0  \n",
       "1        1        1        0  \n",
       "2        1        1        0  \n",
       "3        1        1        0  \n",
       "4        1        1        0  \n",
       "\n",
       "[5 rows x 174 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined_train_maccs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled_maccs= scaler.fit_transform(joined_train_maccs)\n",
    "X_test_scaled_maccs= scaler.fit_transform(joined_test_maccs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "lg2= LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Andreu\\anaconda3\\envs\\ml_project_env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lg2.fit(X_train_scaled_maccs, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "lg_preds2= lg2.predict(X_test_scaled_maccs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmat_lg2 = confusion_matrix(y_test, lg_preds2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7906,   22],\n",
       "       [ 254,   43]], dtype=int64)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmat_lg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.1447811447811448\n",
      "f1_score: 0.23756906077348067\n",
      "roc_auc: 0.5710030850040941\n"
     ]
    }
   ],
   "source": [
    "print(\"Recall:\", recall_score(y_test, lg_preds2))\n",
    "print(\"f1_score:\", f1_score(y_test, lg_preds2))\n",
    "print(\"roc_auc:\", roc_auc_score(y_test, lg_preds2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MACCS encoding doesn't work well with LogReg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_list= []\n",
    "for i in range(1,40, 2):\n",
    "    knn_ex = KNeighborsClassifier(n_neighbors=i)\n",
    "    knn_ex.fit(X_train_scaled, y_train)\n",
    "    knn_y= knn_ex.predict(X_test_scaled) \n",
    "    score_list.append(roc_auc_score(y_test,knn_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "sns.scatterplot(x= range(1,40,2), y= score_list)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_3 = KNeighborsClassifier(n_neighbors=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=3)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_3.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_preds= knn_3.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmat_knn = confusion_matrix(y_test, knn_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7854,   74],\n",
       "       [ 185,  112]], dtype=int64)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmat_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.3771043771043771\n",
      "f1_score: 0.46376811594202905\n",
      "roc_auc: 0.6838851855249434\n"
     ]
    }
   ],
   "source": [
    "print(\"Recall:\", recall_score(y_test, knn_preds))\n",
    "print(\"f1_score:\", f1_score(y_test, knn_preds))\n",
    "print(\"roc_auc:\", roc_auc_score(y_test, knn_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_preds_prob= knn_3.predict_proba(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       ...,\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_preds_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In order to improve the results, first I am going to merge train and valid data, \n",
    "# which will expand the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid= pd.read_csv(\"../data/processed/valid_w_desc.csv\")\n",
    "valid_rdkfp= pd.read_csv(\"../data/processed/valid_rdkfp.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Drug_ID</th>\n",
       "      <th>Drug</th>\n",
       "      <th>Y</th>\n",
       "      <th>mol</th>\n",
       "      <th>tpsa</th>\n",
       "      <th>mol_w</th>\n",
       "      <th>qed</th>\n",
       "      <th>HBA</th>\n",
       "      <th>HBD</th>\n",
       "      <th>logP</th>\n",
       "      <th>MR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Drug 7835</td>\n",
       "      <td>Cc1c2ccnc(C#N)c2c(C)c2c1[nH]c1ccccc12</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;rdkit.Chem.rdchem.Mol object at 0x000002014FB...</td>\n",
       "      <td>52.47</td>\n",
       "      <td>271.110947</td>\n",
       "      <td>0.516388</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4.35782</td>\n",
       "      <td>85.2947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Drug 35410</td>\n",
       "      <td>CN(C)c1ccc(C(Cc2ccccc2)C2NC(=S)NC2=O)cc1</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;rdkit.Chem.rdchem.Mol object at 0x000002014FB...</td>\n",
       "      <td>44.37</td>\n",
       "      <td>339.140533</td>\n",
       "      <td>0.821580</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2.45180</td>\n",
       "      <td>101.3204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Drug 34952</td>\n",
       "      <td>CC(C)=CCOc1cc(O)c2c(O)c3c(cc2c1)CC(C)(C)CC3=O</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;rdkit.Chem.rdchem.Mol object at 0x000002014FB...</td>\n",
       "      <td>66.76</td>\n",
       "      <td>340.167459</td>\n",
       "      <td>0.791283</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4.75110</td>\n",
       "      <td>98.6361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Drug 36154</td>\n",
       "      <td>O=c1onc2c3ccccc3ncn12</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;rdkit.Chem.rdchem.Mol object at 0x000002014FB...</td>\n",
       "      <td>60.40</td>\n",
       "      <td>187.038176</td>\n",
       "      <td>0.522737</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.83570</td>\n",
       "      <td>49.0290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Drug 35825</td>\n",
       "      <td>COc1ccccc1-c1n[nH]c(-c2ccccc2O)n1</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;rdkit.Chem.rdchem.Mol object at 0x000002014FB...</td>\n",
       "      <td>71.03</td>\n",
       "      <td>267.100777</td>\n",
       "      <td>0.765102</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2.85290</td>\n",
       "      <td>75.4715</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Drug_ID                                           Drug  Y  \\\n",
       "0   Drug 7835          Cc1c2ccnc(C#N)c2c(C)c2c1[nH]c1ccccc12  0   \n",
       "1  Drug 35410       CN(C)c1ccc(C(Cc2ccccc2)C2NC(=S)NC2=O)cc1  0   \n",
       "2  Drug 34952  CC(C)=CCOc1cc(O)c2c(O)c3c(cc2c1)CC(C)(C)CC3=O  0   \n",
       "3  Drug 36154                          O=c1onc2c3ccccc3ncn12  0   \n",
       "4  Drug 35825              COc1ccccc1-c1n[nH]c(-c2ccccc2O)n1  0   \n",
       "\n",
       "                                                 mol   tpsa       mol_w  \\\n",
       "0  <rdkit.Chem.rdchem.Mol object at 0x000002014FB...  52.47  271.110947   \n",
       "1  <rdkit.Chem.rdchem.Mol object at 0x000002014FB...  44.37  339.140533   \n",
       "2  <rdkit.Chem.rdchem.Mol object at 0x000002014FB...  66.76  340.167459   \n",
       "3  <rdkit.Chem.rdchem.Mol object at 0x000002014FB...  60.40  187.038176   \n",
       "4  <rdkit.Chem.rdchem.Mol object at 0x000002014FB...  71.03  267.100777   \n",
       "\n",
       "        qed  HBA  HBD     logP        MR  \n",
       "0  0.516388    2    1  4.35782   85.2947  \n",
       "1  0.821580    3    2  2.45180  101.3204  \n",
       "2  0.791283    4    2  4.75110   98.6361  \n",
       "3  0.522737    5    0  0.83570   49.0290  \n",
       "4  0.765102    4    2  2.85290   75.4715  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_valid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_full= df_train.join(train_rdkfp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 28789 entries, 0 to 28788\n",
      "Columns: 2059 entries, Drug_ID to Bit_2047\n",
      "dtypes: float64(5), int64(2051), object(3)\n",
      "memory usage: 452.2+ MB\n"
     ]
    }
   ],
   "source": [
    "train_full.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_full= df_valid.join(valid_rdkfp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4113 entries, 0 to 4112\n",
      "Columns: 2059 entries, Drug_ID to Bit_2047\n",
      "dtypes: float64(5), int64(2051), object(3)\n",
      "memory usage: 64.6+ MB\n"
     ]
    }
   ],
   "source": [
    "valid_full.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = pd.concat([train_full, valid_full])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Drug_ID</th>\n",
       "      <th>Drug</th>\n",
       "      <th>Y</th>\n",
       "      <th>mol</th>\n",
       "      <th>tpsa</th>\n",
       "      <th>mol_w</th>\n",
       "      <th>qed</th>\n",
       "      <th>HBA</th>\n",
       "      <th>HBD</th>\n",
       "      <th>logP</th>\n",
       "      <th>...</th>\n",
       "      <th>Bit_2038</th>\n",
       "      <th>Bit_2039</th>\n",
       "      <th>Bit_2040</th>\n",
       "      <th>Bit_2041</th>\n",
       "      <th>Bit_2042</th>\n",
       "      <th>Bit_2043</th>\n",
       "      <th>Bit_2044</th>\n",
       "      <th>Bit_2045</th>\n",
       "      <th>Bit_2046</th>\n",
       "      <th>Bit_2047</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Drug 0</td>\n",
       "      <td>CCC1=[O+][Cu-3]2([O+]=C(CC)C1)[O+]=C(CC)CC(CC)...</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;rdkit.Chem.rdchem.Mol object at 0x00000201534...</td>\n",
       "      <td>45.20</td>\n",
       "      <td>319.096508</td>\n",
       "      <td>0.434358</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.6669</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Drug 2</td>\n",
       "      <td>CC(=O)N1c2ccccc2Sc2c1ccc1ccccc21</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;rdkit.Chem.rdchem.Mol object at 0x00000201534...</td>\n",
       "      <td>20.31</td>\n",
       "      <td>291.071785</td>\n",
       "      <td>0.581359</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4.9890</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Drug 5</td>\n",
       "      <td>CCOP(=O)(Nc1cccc(Cl)c1)OCC</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;rdkit.Chem.rdchem.Mol object at 0x00000201531...</td>\n",
       "      <td>47.56</td>\n",
       "      <td>263.047808</td>\n",
       "      <td>0.790087</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3.9330</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Drug 6</td>\n",
       "      <td>O=C(O)c1ccccc1O</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;rdkit.Chem.rdchem.Mol object at 0x00000201531...</td>\n",
       "      <td>57.53</td>\n",
       "      <td>138.031694</td>\n",
       "      <td>0.610259</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0904</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Drug 8</td>\n",
       "      <td>O=[N+]([O-])c1ccc(SSc2ccc([N+](=O)[O-])cc2[N+]...</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;rdkit.Chem.rdchem.Mol object at 0x00000201531...</td>\n",
       "      <td>172.56</td>\n",
       "      <td>397.962705</td>\n",
       "      <td>0.374691</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>4.1188</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2059 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Drug_ID                                               Drug  Y  \\\n",
       "0  Drug 0  CCC1=[O+][Cu-3]2([O+]=C(CC)C1)[O+]=C(CC)CC(CC)...  0   \n",
       "1  Drug 2                   CC(=O)N1c2ccccc2Sc2c1ccc1ccccc21  0   \n",
       "2  Drug 5                         CCOP(=O)(Nc1cccc(Cl)c1)OCC  0   \n",
       "3  Drug 6                                    O=C(O)c1ccccc1O  0   \n",
       "4  Drug 8  O=[N+]([O-])c1ccc(SSc2ccc([N+](=O)[O-])cc2[N+]...  0   \n",
       "\n",
       "                                                 mol    tpsa       mol_w  \\\n",
       "0  <rdkit.Chem.rdchem.Mol object at 0x00000201534...   45.20  319.096508   \n",
       "1  <rdkit.Chem.rdchem.Mol object at 0x00000201534...   20.31  291.071785   \n",
       "2  <rdkit.Chem.rdchem.Mol object at 0x00000201531...   47.56  263.047808   \n",
       "3  <rdkit.Chem.rdchem.Mol object at 0x00000201531...   57.53  138.031694   \n",
       "4  <rdkit.Chem.rdchem.Mol object at 0x00000201531...  172.56  397.962705   \n",
       "\n",
       "        qed  HBA  HBD    logP  ...  Bit_2038  Bit_2039  Bit_2040  Bit_2041  \\\n",
       "0  0.434358    0    0  2.6669  ...         0         0         0         0   \n",
       "1  0.581359    2    0  4.9890  ...         1         0         1         1   \n",
       "2  0.790087    3    1  3.9330  ...         1         1         1         0   \n",
       "3  0.610259    3    2  1.0904  ...         0         1         0         0   \n",
       "4  0.374691   10    0  4.1188  ...         0         0         0         1   \n",
       "\n",
       "   Bit_2042  Bit_2043  Bit_2044  Bit_2045  Bit_2046  Bit_2047  \n",
       "0         1         0         1         1         1         0  \n",
       "1         0         0         0         1         1         1  \n",
       "2         0         1         0         1         1         0  \n",
       "3         0         1         0         0         1         0  \n",
       "4         0         1         1         1         1         0  \n",
       "\n",
       "[5 rows x 2059 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 32902 entries, 0 to 4112\n",
      "Columns: 2059 entries, Drug_ID to Bit_2047\n",
      "dtypes: float64(5), int64(2051), object(3)\n",
      "memory usage: 517.1+ MB\n"
     ]
    }
   ],
   "source": [
    "train_set.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_set= train_set.drop(columns=[\"Drug_ID\", \"Drug\", \"mol\", \"Y\"])\n",
    "y_train_set= train_set[\"Y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 32902 entries, 0 to 4112\n",
      "Columns: 2055 entries, tpsa to Bit_2047\n",
      "dtypes: float64(5), int64(2050)\n",
      "memory usage: 516.1 MB\n"
     ]
    }
   ],
   "source": [
    "X_train_set.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "Int64Index: 32902 entries, 0 to 4112\n",
      "Series name: Y\n",
      "Non-Null Count  Dtype\n",
      "--------------  -----\n",
      "32902 non-null  int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 514.1 KB\n"
     ]
    }
   ],
   "source": [
    "y_train_set.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler= MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_set_scaled= scaler.fit_transform(X_train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32902, 2055)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_set_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Andreu\\anaconda3\\envs\\ml_project_env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lg3= LogisticRegression()\n",
    "lg3.fit(X_train_set_scaled, y_train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "lg3_preds= lg3.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7826,  102],\n",
       "       [ 206,   91]], dtype=int64)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmat_lg3 = confusion_matrix(y_test, lg3_preds)\n",
    "cmat_lg3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.3063973063973064\n",
      "f1_score: 0.3714285714285715\n",
      "roc_auc: 0.646765757134072\n"
     ]
    }
   ],
   "source": [
    "print(\"Recall:\", recall_score(y_test, lg3_preds))\n",
    "print(\"f1_score:\", f1_score(y_test, lg3_preds))\n",
    "print(\"roc_auc:\", roc_auc_score(y_test, lg3_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combining both train and validation datasets into a single training set, did not improve the \n",
    "#TP value, but it decreased the number of FP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mInit signature:\u001b[0m\n",
      "\u001b[0mLogisticRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mpenalty\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'l2'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;33m*\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mdual\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mtol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0001\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mC\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mfit_intercept\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mintercept_scaling\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0msolver\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'lbfgs'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mmax_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mmulti_class\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'auto'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mwarm_start\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0ml1_ratio\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mSource:\u001b[0m        \n",
      "\u001b[1;32mclass\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLinearClassifierMixin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSparseCoefMixin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBaseEstimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;34m\"\"\"\n",
      "    Logistic Regression (aka logit, MaxEnt) classifier.\n",
      "\n",
      "    In the multiclass case, the training algorithm uses the one-vs-rest (OvR)\n",
      "    scheme if the 'multi_class' option is set to 'ovr', and uses the\n",
      "    cross-entropy loss if the 'multi_class' option is set to 'multinomial'.\n",
      "    (Currently the 'multinomial' option is supported only by the 'lbfgs',\n",
      "    'sag', 'saga' and 'newton-cg' solvers.)\n",
      "\n",
      "    This class implements regularized logistic regression using the\n",
      "    'liblinear' library, 'newton-cg', 'sag', 'saga' and 'lbfgs' solvers. **Note\n",
      "    that regularization is applied by default**. It can handle both dense\n",
      "    and sparse input. Use C-ordered arrays or CSR matrices containing 64-bit\n",
      "    floats for optimal performance; any other input format will be converted\n",
      "    (and copied).\n",
      "\n",
      "    The 'newton-cg', 'sag', and 'lbfgs' solvers support only L2 regularization\n",
      "    with primal formulation, or no regularization. The 'liblinear' solver\n",
      "    supports both L1 and L2 regularization, with a dual formulation only for\n",
      "    the L2 penalty. The Elastic-Net regularization is only supported by the\n",
      "    'saga' solver.\n",
      "\n",
      "    Read more in the :ref:`User Guide <logistic_regression>`.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    penalty : {'l1', 'l2', 'elasticnet', 'none'}, default='l2'\n",
      "        Specify the norm of the penalty:\n",
      "\n",
      "        - `'none'`: no penalty is added;\n",
      "        - `'l2'`: add a L2 penalty term and it is the default choice;\n",
      "        - `'l1'`: add a L1 penalty term;\n",
      "        - `'elasticnet'`: both L1 and L2 penalty terms are added.\n",
      "\n",
      "        .. warning::\n",
      "           Some penalties may not work with some solvers. See the parameter\n",
      "           `solver` below, to know the compatibility between the penalty and\n",
      "           solver.\n",
      "\n",
      "        .. versionadded:: 0.19\n",
      "           l1 penalty with SAGA solver (allowing 'multinomial' + L1)\n",
      "\n",
      "    dual : bool, default=False\n",
      "        Dual or primal formulation. Dual formulation is only implemented for\n",
      "        l2 penalty with liblinear solver. Prefer dual=False when\n",
      "        n_samples > n_features.\n",
      "\n",
      "    tol : float, default=1e-4\n",
      "        Tolerance for stopping criteria.\n",
      "\n",
      "    C : float, default=1.0\n",
      "        Inverse of regularization strength; must be a positive float.\n",
      "        Like in support vector machines, smaller values specify stronger\n",
      "        regularization.\n",
      "\n",
      "    fit_intercept : bool, default=True\n",
      "        Specifies if a constant (a.k.a. bias or intercept) should be\n",
      "        added to the decision function.\n",
      "\n",
      "    intercept_scaling : float, default=1\n",
      "        Useful only when the solver 'liblinear' is used\n",
      "        and self.fit_intercept is set to True. In this case, x becomes\n",
      "        [x, self.intercept_scaling],\n",
      "        i.e. a \"synthetic\" feature with constant value equal to\n",
      "        intercept_scaling is appended to the instance vector.\n",
      "        The intercept becomes ``intercept_scaling * synthetic_feature_weight``.\n",
      "\n",
      "        Note! the synthetic feature weight is subject to l1/l2 regularization\n",
      "        as all other features.\n",
      "        To lessen the effect of regularization on synthetic feature weight\n",
      "        (and therefore on the intercept) intercept_scaling has to be increased.\n",
      "\n",
      "    class_weight : dict or 'balanced', default=None\n",
      "        Weights associated with classes in the form ``{class_label: weight}``.\n",
      "        If not given, all classes are supposed to have weight one.\n",
      "\n",
      "        The \"balanced\" mode uses the values of y to automatically adjust\n",
      "        weights inversely proportional to class frequencies in the input data\n",
      "        as ``n_samples / (n_classes * np.bincount(y))``.\n",
      "\n",
      "        Note that these weights will be multiplied with sample_weight (passed\n",
      "        through the fit method) if sample_weight is specified.\n",
      "\n",
      "        .. versionadded:: 0.17\n",
      "           *class_weight='balanced'*\n",
      "\n",
      "    random_state : int, RandomState instance, default=None\n",
      "        Used when ``solver`` == 'sag', 'saga' or 'liblinear' to shuffle the\n",
      "        data. See :term:`Glossary <random_state>` for details.\n",
      "\n",
      "    solver : {'newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'}, \\\n",
      "            default='lbfgs'\n",
      "\n",
      "        Algorithm to use in the optimization problem. Default is 'lbfgs'.\n",
      "        To choose a solver, you might want to consider the following aspects:\n",
      "\n",
      "            - For small datasets, 'liblinear' is a good choice, whereas 'sag'\n",
      "              and 'saga' are faster for large ones;\n",
      "            - For multiclass problems, only 'newton-cg', 'sag', 'saga' and\n",
      "              'lbfgs' handle multinomial loss;\n",
      "            - 'liblinear' is limited to one-versus-rest schemes.\n",
      "\n",
      "        .. warning::\n",
      "           The choice of the algorithm depends on the penalty chosen:\n",
      "           Supported penalties by solver:\n",
      "\n",
      "           - 'newton-cg'   -   ['l2', 'none']\n",
      "           - 'lbfgs'       -   ['l2', 'none']\n",
      "           - 'liblinear'   -   ['l1', 'l2']\n",
      "           - 'sag'         -   ['l2', 'none']\n",
      "           - 'saga'        -   ['elasticnet', 'l1', 'l2', 'none']\n",
      "\n",
      "        .. note::\n",
      "           'sag' and 'saga' fast convergence is only guaranteed on\n",
      "           features with approximately the same scale. You can\n",
      "           preprocess the data with a scaler from :mod:`sklearn.preprocessing`.\n",
      "\n",
      "        .. seealso::\n",
      "           Refer to the User Guide for more information regarding\n",
      "           :class:`LogisticRegression` and more specifically the\n",
      "           `Table <https://scikit-learn.org/dev/modules/linear_model.html#logistic-regression>`_\n",
      "           summarazing solver/penalty supports.\n",
      "           <!--\n",
      "           # noqa: E501\n",
      "           -->\n",
      "\n",
      "        .. versionadded:: 0.17\n",
      "           Stochastic Average Gradient descent solver.\n",
      "        .. versionadded:: 0.19\n",
      "           SAGA solver.\n",
      "        .. versionchanged:: 0.22\n",
      "            The default solver changed from 'liblinear' to 'lbfgs' in 0.22.\n",
      "\n",
      "    max_iter : int, default=100\n",
      "        Maximum number of iterations taken for the solvers to converge.\n",
      "\n",
      "    multi_class : {'auto', 'ovr', 'multinomial'}, default='auto'\n",
      "        If the option chosen is 'ovr', then a binary problem is fit for each\n",
      "        label. For 'multinomial' the loss minimised is the multinomial loss fit\n",
      "        across the entire probability distribution, *even when the data is\n",
      "        binary*. 'multinomial' is unavailable when solver='liblinear'.\n",
      "        'auto' selects 'ovr' if the data is binary, or if solver='liblinear',\n",
      "        and otherwise selects 'multinomial'.\n",
      "\n",
      "        .. versionadded:: 0.18\n",
      "           Stochastic Average Gradient descent solver for 'multinomial' case.\n",
      "        .. versionchanged:: 0.22\n",
      "            Default changed from 'ovr' to 'auto' in 0.22.\n",
      "\n",
      "    verbose : int, default=0\n",
      "        For the liblinear and lbfgs solvers set verbose to any positive\n",
      "        number for verbosity.\n",
      "\n",
      "    warm_start : bool, default=False\n",
      "        When set to True, reuse the solution of the previous call to fit as\n",
      "        initialization, otherwise, just erase the previous solution.\n",
      "        Useless for liblinear solver. See :term:`the Glossary <warm_start>`.\n",
      "\n",
      "        .. versionadded:: 0.17\n",
      "           *warm_start* to support *lbfgs*, *newton-cg*, *sag*, *saga* solvers.\n",
      "\n",
      "    n_jobs : int, default=None\n",
      "        Number of CPU cores used when parallelizing over classes if\n",
      "        multi_class='ovr'\". This parameter is ignored when the ``solver`` is\n",
      "        set to 'liblinear' regardless of whether 'multi_class' is specified or\n",
      "        not. ``None`` means 1 unless in a :obj:`joblib.parallel_backend`\n",
      "        context. ``-1`` means using all processors.\n",
      "        See :term:`Glossary <n_jobs>` for more details.\n",
      "\n",
      "    l1_ratio : float, default=None\n",
      "        The Elastic-Net mixing parameter, with ``0 <= l1_ratio <= 1``. Only\n",
      "        used if ``penalty='elasticnet'``. Setting ``l1_ratio=0`` is equivalent\n",
      "        to using ``penalty='l2'``, while setting ``l1_ratio=1`` is equivalent\n",
      "        to using ``penalty='l1'``. For ``0 < l1_ratio <1``, the penalty is a\n",
      "        combination of L1 and L2.\n",
      "\n",
      "    Attributes\n",
      "    ----------\n",
      "\n",
      "    classes_ : ndarray of shape (n_classes, )\n",
      "        A list of class labels known to the classifier.\n",
      "\n",
      "    coef_ : ndarray of shape (1, n_features) or (n_classes, n_features)\n",
      "        Coefficient of the features in the decision function.\n",
      "\n",
      "        `coef_` is of shape (1, n_features) when the given problem is binary.\n",
      "        In particular, when `multi_class='multinomial'`, `coef_` corresponds\n",
      "        to outcome 1 (True) and `-coef_` corresponds to outcome 0 (False).\n",
      "\n",
      "    intercept_ : ndarray of shape (1,) or (n_classes,)\n",
      "        Intercept (a.k.a. bias) added to the decision function.\n",
      "\n",
      "        If `fit_intercept` is set to False, the intercept is set to zero.\n",
      "        `intercept_` is of shape (1,) when the given problem is binary.\n",
      "        In particular, when `multi_class='multinomial'`, `intercept_`\n",
      "        corresponds to outcome 1 (True) and `-intercept_` corresponds to\n",
      "        outcome 0 (False).\n",
      "\n",
      "    n_features_in_ : int\n",
      "        Number of features seen during :term:`fit`.\n",
      "\n",
      "        .. versionadded:: 0.24\n",
      "\n",
      "    feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
      "        Names of features seen during :term:`fit`. Defined only when `X`\n",
      "        has feature names that are all strings.\n",
      "\n",
      "        .. versionadded:: 1.0\n",
      "\n",
      "    n_iter_ : ndarray of shape (n_classes,) or (1, )\n",
      "        Actual number of iterations for all classes. If binary or multinomial,\n",
      "        it returns only 1 element. For liblinear solver, only the maximum\n",
      "        number of iteration across all classes is given.\n",
      "\n",
      "        .. versionchanged:: 0.20\n",
      "\n",
      "            In SciPy <= 1.0.0 the number of lbfgs iterations may exceed\n",
      "            ``max_iter``. ``n_iter_`` will now report at most ``max_iter``.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    SGDClassifier : Incrementally trained logistic regression (when given\n",
      "        the parameter ``loss=\"log\"``).\n",
      "    LogisticRegressionCV : Logistic regression with built-in cross validation.\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    The underlying C implementation uses a random number generator to\n",
      "    select features when fitting the model. It is thus not uncommon,\n",
      "    to have slightly different results for the same input data. If\n",
      "    that happens, try with a smaller tol parameter.\n",
      "\n",
      "    Predict output may not match that of standalone liblinear in certain\n",
      "    cases. See :ref:`differences from liblinear <liblinear_differences>`\n",
      "    in the narrative documentation.\n",
      "\n",
      "    References\n",
      "    ----------\n",
      "\n",
      "    L-BFGS-B -- Software for Large-scale Bound-constrained Optimization\n",
      "        Ciyou Zhu, Richard Byrd, Jorge Nocedal and Jose Luis Morales.\n",
      "        http://users.iems.northwestern.edu/~nocedal/lbfgsb.html\n",
      "\n",
      "    LIBLINEAR -- A Library for Large Linear Classification\n",
      "        https://www.csie.ntu.edu.tw/~cjlin/liblinear/\n",
      "\n",
      "    SAG -- Mark Schmidt, Nicolas Le Roux, and Francis Bach\n",
      "        Minimizing Finite Sums with the Stochastic Average Gradient\n",
      "        https://hal.inria.fr/hal-00860051/document\n",
      "\n",
      "    SAGA -- Defazio, A., Bach F. & Lacoste-Julien S. (2014).\n",
      "        SAGA: A Fast Incremental Gradient Method With Support\n",
      "        for Non-Strongly Convex Composite Objectives\n",
      "        https://arxiv.org/abs/1407.0202\n",
      "\n",
      "    Hsiang-Fu Yu, Fang-Lan Huang, Chih-Jen Lin (2011). Dual coordinate descent\n",
      "        methods for logistic regression and maximum entropy models.\n",
      "        Machine Learning 85(1-2):41-75.\n",
      "        https://www.csie.ntu.edu.tw/~cjlin/papers/maxent_dual.pdf\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> from sklearn.datasets import load_iris\n",
      "    >>> from sklearn.linear_model import LogisticRegression\n",
      "    >>> X, y = load_iris(return_X_y=True)\n",
      "    >>> clf = LogisticRegression(random_state=0).fit(X, y)\n",
      "    >>> clf.predict(X[:2, :])\n",
      "    array([0, 0])\n",
      "    >>> clf.predict_proba(X[:2, :])\n",
      "    array([[9.8...e-01, 1.8...e-02, 1.4...e-08],\n",
      "           [9.7...e-01, 2.8...e-02, ...e-08]])\n",
      "    >>> clf.score(X, y)\n",
      "    0.97...\n",
      "    \"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mpenalty\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"l2\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;33m*\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mdual\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mtol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1e-4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mC\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mfit_intercept\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mintercept_scaling\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0msolver\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"lbfgs\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mmax_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mmulti_class\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"auto\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mwarm_start\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0ml1_ratio\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpenalty\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpenalty\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdual\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdual\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtol\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtol\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mC\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mC\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_intercept\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_intercept\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintercept_scaling\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mintercept_scaling\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclass_weight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msolver\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msolver\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_iter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmulti_class\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmulti_class\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarm_start\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwarm_start\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_jobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0ml1_ratio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ml1_ratio\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;34m\"\"\"\n",
      "        Fit the model according to the given training data.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      "            Training vector, where `n_samples` is the number of samples and\n",
      "            `n_features` is the number of features.\n",
      "\n",
      "        y : array-like of shape (n_samples,)\n",
      "            Target vector relative to X.\n",
      "\n",
      "        sample_weight : array-like of shape (n_samples,) default=None\n",
      "            Array of weights that are assigned to individual samples.\n",
      "            If not provided, then each sample is given unit weight.\n",
      "\n",
      "            .. versionadded:: 0.17\n",
      "               *sample_weight* support to LogisticRegression.\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        self\n",
      "            Fitted estimator.\n",
      "\n",
      "        Notes\n",
      "        -----\n",
      "        The SAGA solver supports both float64 and float32 bit arrays.\n",
      "        \"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0msolver\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_solver\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msolver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdual\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mC\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumbers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNumber\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mC\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Penalty term must be positive; got (C=%r)\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mC\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpenalty\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"elasticnet\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0ml1_ratio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumbers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNumber\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0ml1_ratio\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0ml1_ratio\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                    \u001b[1;34m\"l1_ratio must be between 0 and 1; got (l1_ratio=%r)\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                    \u001b[1;33m%\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0ml1_ratio\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0ml1_ratio\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[1;34m\"l1_ratio parameter is only used when penalty is \"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[1;34m\"'elasticnet'. Got \"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[1;34m\"(penalty={})\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpenalty\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"none\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mC\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# default values\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                    \u001b[1;34m\"Setting penalty='none' will ignore the C and l1_ratio parameters\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[1;31m# Note that check for l1_ratio is done right above\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mC_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minf\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mpenalty\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"l2\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mC_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mC\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mpenalty\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumbers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNumber\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_iter\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[1;34m\"Maximum number of iteration must be positive; got (max_iter=%r)\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[1;33m%\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumbers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNumber\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtol\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[1;34m\"Tolerance for stopping criteria must be positive; got (tol=%r)\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[1;33m%\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtol\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0msolver\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"lbfgs\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0m_dtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0m_dtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"csr\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_dtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"C\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0maccept_large_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msolver\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"liblinear\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"sag\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"saga\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mcheck_classification_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mmulti_class\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_multi_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmulti_class\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msolver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0msolver\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"liblinear\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;32mif\u001b[0m \u001b[0meffective_n_jobs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                    \u001b[1;34m\"'n_jobs' > 1 does not have any effect when\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                    \u001b[1;34m\" 'solver' is set to 'liblinear'. Got 'n_jobs'\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                    \u001b[1;34m\" = {}.\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meffective_n_jobs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintercept_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_iter_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_fit_liblinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mC\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_intercept\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintercept_scaling\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdual\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtol\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_iter_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn_iter_\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0msolver\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"sag\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"saga\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mmax_squared_sum\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrow_norms\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msquared\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mmax_squared_sum\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mn_classes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mclasses_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0mn_classes\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[1;34m\"This solver needs samples of at least 2 classes\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[1;34m\" in the data, but the data contains only one\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[1;34m\" class: %r\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[1;33m%\u001b[0m \u001b[0mclasses_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mn_classes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mclasses_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclasses_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarm_start\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mwarm_start_coef\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"coef_\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mwarm_start_coef\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0mwarm_start_coef\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_intercept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mwarm_start_coef\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mwarm_start_coef\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintercept_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;31m# Hack so that we iterate only once for the multinomial case.\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0mmulti_class\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"multinomial\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mclasses_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mwarm_start_coef\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mwarm_start_coef\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0mwarm_start_coef\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mwarm_start_coef\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mn_classes\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mpath_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdelayed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_logistic_regression_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;31m# The SAG solver releases the GIL so it's more efficient to use\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;31m# threads for this solver.\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0msolver\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"sag\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"saga\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mprefer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"threads\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mprefer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"processes\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mfold_coefs_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mParallel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;33m**\u001b[0m\u001b[0m_joblib_parallel_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprefer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprefer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mpath_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mpos_class\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mCs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mC_\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0ml1_ratio\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0ml1_ratio\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mfit_intercept\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_intercept\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mtol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtol\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0msolver\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msolver\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mmulti_class\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmulti_class\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mmax_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mcoef\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mwarm_start_coef_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mpenalty\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mmax_squared_sum\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_squared_sum\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;32mfor\u001b[0m \u001b[0mclass_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwarm_start_coef_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwarm_start_coef\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mfold_coefs_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_iter_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfold_coefs_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_iter_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_iter_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mn_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0mmulti_class\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"multinomial\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoef_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfold_coefs_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoef_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfold_coefs_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoef_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mn_classes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_features\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_intercept\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_intercept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintercept_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoef_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintercept_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_classes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;34m\"\"\"\n",
      "        Probability estimates.\n",
      "\n",
      "        The returned estimates for all classes are ordered by the\n",
      "        label of classes.\n",
      "\n",
      "        For a multi_class problem, if multi_class is set to be \"multinomial\"\n",
      "        the softmax function is used to find the predicted probability of\n",
      "        each class.\n",
      "        Else use a one-vs-rest approach, i.e calculate the probability\n",
      "        of each class assuming it to be positive using the logistic function.\n",
      "        and normalize these values across all the classes.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        X : array-like of shape (n_samples, n_features)\n",
      "            Vector to be scored, where `n_samples` is the number of samples and\n",
      "            `n_features` is the number of features.\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        T : array-like of shape (n_samples, n_classes)\n",
      "            Returns the probability of the sample for each class in the model,\n",
      "            where classes are ordered as they are in ``self.classes_``.\n",
      "        \"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0movr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmulti_class\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"ovr\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"warn\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmulti_class\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"auto\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msolver\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"liblinear\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0movr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_predict_proba_lr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mdecision\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;32mif\u001b[0m \u001b[0mdecision\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[1;31m# Workaround for multi_class=\"multinomial\" and binary outcomes\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[1;31m# which requires softmax prediction with only a 1D decision.\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mdecision_2d\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mdecision\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecision\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mdecision_2d\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdecision\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;32mreturn\u001b[0m \u001b[0msoftmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdecision_2d\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0mpredict_log_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;34m\"\"\"\n",
      "        Predict logarithm of probability estimates.\n",
      "\n",
      "        The returned estimates for all classes are ordered by the\n",
      "        label of classes.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        X : array-like of shape (n_samples, n_features)\n",
      "            Vector to be scored, where `n_samples` is the number of samples and\n",
      "            `n_features` is the number of features.\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        T : array-like of shape (n_samples, n_classes)\n",
      "            Returns the log-probability of the sample for each class in the\n",
      "            model, where classes are ordered as they are in ``self.classes_``.\n",
      "        \"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFile:\u001b[0m           c:\\users\\andreu\\anaconda3\\envs\\ml_project_env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\n",
      "\u001b[1;31mType:\u001b[0m           type\n",
      "\u001b[1;31mSubclasses:\u001b[0m     LogisticRegressionCV\n"
     ]
    }
   ],
   "source": [
    "LogisticRegression??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_lr = {                      \n",
    "    'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "    #'C': [0.01, 0.1, 1],   \n",
    "    'class_weight': ['balanced']                                    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold= StratifiedKFold(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "\n",
    "grid = GridSearchCV(estimator = lr,\n",
    "                  param_grid = param_grid_lr,\n",
    "                  n_jobs=-1,\n",
    "                  cv = kfold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32902, 2055)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_set_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             estimator=LogisticRegression(), n_jobs=-1,\n",
       "             param_grid={'class_weight': ['balanced'],\n",
       "                         'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag',\n",
       "                                    'saga']})"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X_train_set_scaled, y_train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced', solver='newton-cg')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_preds= grid.best_estimator_.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(test, pred):\n",
    "    cmat = confusion_matrix(test, pred)\n",
    "    print(cmat)\n",
    "    print(\"Recall:\", recall_score(test, pred))\n",
    "    print(\"f1_score:\", f1_score(test, pred))\n",
    "    print(\"roc_auc:\", roc_auc_score(test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7077  851]\n",
      " [ 135  162]]\n",
      "Recall: 0.5454545454545454\n",
      "f1_score: 0.24732824427480915\n",
      "roc_auc: 0.7190567379139529\n"
     ]
    }
   ],
   "source": [
    "evaluate(y_test, best_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#balancing the method yielded too many FP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weight= {0: 1, 1: 5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "lg4 = LogisticRegression(solver='newton-cg', class_weight=class_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight={0: 1, 1: 5}, solver='newton-cg')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lg4.fit(X_train_set_scaled, y_train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "lg4_preds= lg4.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7531  397]\n",
      " [ 162  135]]\n",
      "Recall: 0.45454545454545453\n",
      "f1_score: 0.3256936067551267\n",
      "roc_auc: 0.7022348867076414\n"
     ]
    }
   ],
   "source": [
    "evaluate(y_test, lg4_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 518. GiB for an array with shape (32902, 2114596) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [74], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m poly \u001b[39m=\u001b[39m PolynomialFeatures(degree \u001b[39m=\u001b[39m \u001b[39m2\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m X_poly_2 \u001b[39m=\u001b[39m poly\u001b[39m.\u001b[39;49mfit_transform(X_train_set_scaled)\n",
      "File \u001b[1;32mc:\\Users\\Andreu\\anaconda3\\envs\\ml_project_env\\lib\\site-packages\\sklearn\\base.py:852\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    848\u001b[0m \u001b[39m# non-optimized default implementation; override when a better\u001b[39;00m\n\u001b[0;32m    849\u001b[0m \u001b[39m# method is possible for a given clustering algorithm\u001b[39;00m\n\u001b[0;32m    850\u001b[0m \u001b[39mif\u001b[39;00m y \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    851\u001b[0m     \u001b[39m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[1;32m--> 852\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit(X, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\u001b[39m.\u001b[39;49mtransform(X)\n\u001b[0;32m    853\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    854\u001b[0m     \u001b[39m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[0;32m    855\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n",
      "File \u001b[1;32mc:\\Users\\Andreu\\anaconda3\\envs\\ml_project_env\\lib\\site-packages\\sklearn\\preprocessing\\_polynomial.py:421\u001b[0m, in \u001b[0;36mPolynomialFeatures.transform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    417\u001b[0m     XP \u001b[39m=\u001b[39m sparse\u001b[39m.\u001b[39mhstack(columns, dtype\u001b[39m=\u001b[39mX\u001b[39m.\u001b[39mdtype)\u001b[39m.\u001b[39mtocsc()\n\u001b[0;32m    418\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    419\u001b[0m     \u001b[39m# Do as if _min_degree = 0 and cut down array after the\u001b[39;00m\n\u001b[0;32m    420\u001b[0m     \u001b[39m# computation, i.e. use _n_out_full instead of n_output_features_.\u001b[39;00m\n\u001b[1;32m--> 421\u001b[0m     XP \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mempty(\n\u001b[0;32m    422\u001b[0m         shape\u001b[39m=\u001b[39;49m(n_samples, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_n_out_full), dtype\u001b[39m=\u001b[39;49mX\u001b[39m.\u001b[39;49mdtype, order\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49morder\n\u001b[0;32m    423\u001b[0m     )\n\u001b[0;32m    425\u001b[0m     \u001b[39m# What follows is a faster implementation of:\u001b[39;00m\n\u001b[0;32m    426\u001b[0m     \u001b[39m# for i, comb in enumerate(combinations):\u001b[39;00m\n\u001b[0;32m    427\u001b[0m     \u001b[39m#     XP[:, i] = X[:, comb].prod(1)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    437\u001b[0m \n\u001b[0;32m    438\u001b[0m     \u001b[39m# degree 0 term\u001b[39;00m\n\u001b[0;32m    439\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minclude_bias:\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 518. GiB for an array with shape (32902, 2114596) and data type float64"
     ]
    }
   ],
   "source": [
    "poly = PolynomialFeatures(degree = 2)\n",
    "X_poly_2 = poly.fit_transform(X_train_set_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.to_csv(\"../data/processed/train_set.csv\", index=False)#to work on google colab\n",
    "test_set= df_test.join(test_rdkfp)\n",
    "test_set.to_csv(\"../data/processed/test_set.csv\", index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Polynomial features crashes both in hard disk and google colab. Too big for the RAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.fit(X_train_set_scaled, y_train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_preds= dt.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7513  415]\n",
      " [ 198   99]]\n",
      "Recall: 0.3333333333333333\n",
      "f1_score: 0.24414303329223178\n",
      "roc_auc: 0.6404936091490078\n"
     ]
    }
   ],
   "source": [
    "evaluate(y_test, dt_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_clf = RandomForestClassifier(n_estimators=3,\n",
    "                                 max_features=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_features=2, n_estimators=3)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_clf.fit(X_train_set_scaled, y_train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_preds= rnd_clf.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7873   55]\n",
      " [ 225   72]]\n",
      "Recall: 0.24242424242424243\n",
      "f1_score: 0.339622641509434\n",
      "roc_auc: 0.6177434027459254\n"
     ]
    }
   ],
   "source": [
    "evaluate(y_test, rnd_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 1, 1: 5}"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators= 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=200)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(X_train_set_scaled, y_train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_preds= rf.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7913   15]\n",
      " [ 229   68]]\n",
      "Recall: 0.22895622895622897\n",
      "f1_score: 0.35789473684210527\n",
      "roc_auc: 0.6135321003509703\n"
     ]
    }
   ],
   "source": [
    "evaluate(y_test, rf_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf2 = RandomForestClassifier(n_estimators=200,\n",
    "                            class_weight=class_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(class_weight={0: 1, 1: 5}, n_estimators=200)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf2.fit(X_train_set_scaled, y_train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf2_preds = rf2.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7913   15]\n",
      " [ 227   70]]\n",
      "Recall: 0.2356902356902357\n",
      "f1_score: 0.36649214659685864\n",
      "roc_auc: 0.6168991037179735\n"
     ]
    }
   ],
   "source": [
    "evaluate(y_test, rf2_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf3 = RandomForestClassifier(n_estimators=200,\n",
    "                            max_features=2,\n",
    "                            class_weight=\"balanced\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(class_weight='balanced', max_features=2,\n",
       "                       n_estimators=200)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf3.fit(X_train_set_scaled, y_train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf3_preds= rf3.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7918   10]\n",
      " [ 237   60]]\n",
      "Recall: 0.20202020202020202\n",
      "f1_score: 0.32697547683923706\n",
      "roc_auc: 0.6003794249253381\n"
     ]
    }
   ],
   "source": [
    "evaluate(y_test, rf3_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf4= RandomForestClassifier(n_estimators=200,\n",
    "                            class_weight=\"balanced\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(class_weight='balanced', n_estimators=200)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf4.fit(X_train_set_scaled, y_train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf4_preds= rf4.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7915   13]\n",
      " [ 231   66]]\n",
      "Recall: 0.2222222222222222\n",
      "f1_score: 0.351063829787234\n",
      "roc_auc: 0.6102912322009194\n"
     ]
    }
   ],
   "source": [
    "evaluate(y_test, rf4_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf5= RandomForestClassifier(n_estimators=100,\n",
    "                            class_weight={0: 1, 1: 100})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(class_weight={0: 1, 1: 100})"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf5.fit(X_train_set_scaled, y_train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf5_preds= rf5.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7915   13]\n",
      " [ 235   62]]\n",
      "Recall: 0.20875420875420875\n",
      "f1_score: 0.33333333333333337\n",
      "roc_auc: 0.6035572254669126\n"
     ]
    }
   ],
   "source": [
    "evaluate(y_test, rf5_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_list= []\n",
    "for i in range(1,20, 2):\n",
    "    knn_ex = KNeighborsClassifier(n_neighbors=i)\n",
    "    knn_ex.fit(X_train_set_scaled, y_train_set)\n",
    "    knn_y= knn_ex.predict(X_test_scaled) \n",
    "    score_list.append(roc_auc_score(y_test,knn_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "sns.scatterplot(x= range(1,20,2), y= score_list)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_knn = {\"n_neighbors\": [1,3,5,7],\n",
    "                \"weights\": [\"uniform\", \"distance\"],\n",
    "                \"algorithm\": [\"ball_tree\", \"kd_tree\"]}           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_1 = KNeighborsClassifier(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=1)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_1.fit(X_train_set_scaled,y_train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn1_preds= knn_1.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7763  165]\n",
      " [ 168  129]]\n",
      "Recall: 0.43434343434343436\n",
      "f1_score: 0.43654822335025373\n",
      "roc_auc: 0.7067655617731298\n"
     ]
    }
   ],
   "source": [
    "evaluate(y_test, knn1_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_3 = KNeighborsClassifier(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=3)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_3.fit(X_train_set_scaled,y_train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn3_preds= knn_3.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7856   72]\n",
      " [ 190  107]]\n",
      "Recall: 0.3602693602693603\n",
      "f1_score: 0.4495798319327731\n",
      "roc_auc: 0.6755938123243875\n"
     ]
    }
   ],
   "source": [
    "evaluate(y_test, knn3_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_1_2 = KNeighborsClassifier(1, weights=\"distance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=1, weights='distance')"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_1_2.fit(X_train_set_scaled,y_train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn1_2_preds= knn_1_2.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7763  165]\n",
      " [ 168  129]]\n",
      "Recall: 0.43434343434343436\n",
      "f1_score: 0.43654822335025373\n",
      "roc_auc: 0.7067655617731298\n"
     ]
    }
   ],
   "source": [
    "evaluate(y_test, knn1_2_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC(kernel=\"linear\", C= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [144], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m svc\u001b[39m.\u001b[39;49mfit(X_train_set_scaled,y_train_set)\n\u001b[0;32m      2\u001b[0m svc_preds\u001b[39m=\u001b[39m svc\u001b[39m.\u001b[39mpredict(X_test_scaled)\n",
      "File \u001b[1;32mc:\\Users\\Andreu\\anaconda3\\envs\\ml_project_env\\lib\\site-packages\\sklearn\\svm\\_base.py:255\u001b[0m, in \u001b[0;36mBaseLibSVM.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    252\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m[LibSVM]\u001b[39m\u001b[39m\"\u001b[39m, end\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    254\u001b[0m seed \u001b[39m=\u001b[39m rnd\u001b[39m.\u001b[39mrandint(np\u001b[39m.\u001b[39miinfo(\u001b[39m\"\u001b[39m\u001b[39mi\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mmax)\n\u001b[1;32m--> 255\u001b[0m fit(X, y, sample_weight, solver_type, kernel, random_seed\u001b[39m=\u001b[39;49mseed)\n\u001b[0;32m    256\u001b[0m \u001b[39m# see comment on the other call to np.iinfo in this file\u001b[39;00m\n\u001b[0;32m    258\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshape_fit_ \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mshape \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(X, \u001b[39m\"\u001b[39m\u001b[39mshape\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39melse\u001b[39;00m (n_samples,)\n",
      "File \u001b[1;32mc:\\Users\\Andreu\\anaconda3\\envs\\ml_project_env\\lib\\site-packages\\sklearn\\svm\\_base.py:315\u001b[0m, in \u001b[0;36mBaseLibSVM._dense_fit\u001b[1;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[0;32m    302\u001b[0m libsvm\u001b[39m.\u001b[39mset_verbosity_wrap(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose)\n\u001b[0;32m    304\u001b[0m \u001b[39m# we don't pass **self.get_params() to allow subclasses to\u001b[39;00m\n\u001b[0;32m    305\u001b[0m \u001b[39m# add other parameters to __init__\u001b[39;00m\n\u001b[0;32m    306\u001b[0m (\n\u001b[0;32m    307\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msupport_,\n\u001b[0;32m    308\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msupport_vectors_,\n\u001b[0;32m    309\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_support,\n\u001b[0;32m    310\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdual_coef_,\n\u001b[0;32m    311\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mintercept_,\n\u001b[0;32m    312\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_probA,\n\u001b[0;32m    313\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_probB,\n\u001b[0;32m    314\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit_status_,\n\u001b[1;32m--> 315\u001b[0m ) \u001b[39m=\u001b[39m libsvm\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m    316\u001b[0m     X,\n\u001b[0;32m    317\u001b[0m     y,\n\u001b[0;32m    318\u001b[0m     svm_type\u001b[39m=\u001b[39;49msolver_type,\n\u001b[0;32m    319\u001b[0m     sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m    320\u001b[0m     class_weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclass_weight_,\n\u001b[0;32m    321\u001b[0m     kernel\u001b[39m=\u001b[39;49mkernel,\n\u001b[0;32m    322\u001b[0m     C\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mC,\n\u001b[0;32m    323\u001b[0m     nu\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnu,\n\u001b[0;32m    324\u001b[0m     probability\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprobability,\n\u001b[0;32m    325\u001b[0m     degree\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdegree,\n\u001b[0;32m    326\u001b[0m     shrinking\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mshrinking,\n\u001b[0;32m    327\u001b[0m     tol\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtol,\n\u001b[0;32m    328\u001b[0m     cache_size\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcache_size,\n\u001b[0;32m    329\u001b[0m     coef0\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcoef0,\n\u001b[0;32m    330\u001b[0m     gamma\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_gamma,\n\u001b[0;32m    331\u001b[0m     epsilon\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mepsilon,\n\u001b[0;32m    332\u001b[0m     max_iter\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_iter,\n\u001b[0;32m    333\u001b[0m     random_seed\u001b[39m=\u001b[39;49mrandom_seed,\n\u001b[0;32m    334\u001b[0m )\n\u001b[0;32m    336\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_warn_from_fit_status()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "svc.fit(X_train_set_scaled,y_train_set)\n",
    "svc_preds= svc.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(y_test, svc_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada = AdaBoostClassifier(lg3, n_estimators=100)\n",
    "\n",
    "ada.fit(X_train_set_scaled, y_train_set)\n",
    "\n",
    "ada_preds = ada.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7866   62]\n",
      " [ 224   73]]\n",
      "Recall: 0.24579124579124578\n",
      "f1_score: 0.33796296296296297\n",
      "roc_auc: 0.6189854311700931\n"
     ]
    }
   ],
   "source": [
    "evaluate(y_test, ada_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_lg4 = AdaBoostClassifier(lg4, n_estimators=100)\n",
    "\n",
    "ada_lg4.fit(X_train_set_scaled, y_train_set)\n",
    "\n",
    "ada_preds_lg4 = ada_lg4.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7643  285]\n",
      " [ 171  126]]\n",
      "Recall: 0.42424242424242425\n",
      "f1_score: 0.35593220338983056\n",
      "roc_auc: 0.6941469437054705\n"
     ]
    }
   ],
   "source": [
    "evaluate(y_test, ada_preds_lg4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../model/ada_lg_model.pkl\", \"wb\") as save_file:\n",
    "    pickle.dump(ada_lg4, save_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "KNeighborsClassifier doesn't support sample_weight.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [155], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m ada_knn1 \u001b[39m=\u001b[39m AdaBoostClassifier(knn_1, n_estimators\u001b[39m=\u001b[39m\u001b[39m100\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m ada_knn1\u001b[39m.\u001b[39;49mfit(X_train_set_scaled, y_train_set)\n\u001b[0;32m      5\u001b[0m ada_knn1 \u001b[39m=\u001b[39m ada_knn1\u001b[39m.\u001b[39mpredict(X_test_scaled)\n",
      "File \u001b[1;32mc:\\Users\\Andreu\\anaconda3\\envs\\ml_project_env\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:486\u001b[0m, in \u001b[0;36mAdaBoostClassifier.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    483\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39malgorithm \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m is not supported\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39malgorithm)\n\u001b[0;32m    485\u001b[0m \u001b[39m# Fit\u001b[39;00m\n\u001b[1;32m--> 486\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit(X, y, sample_weight)\n",
      "File \u001b[1;32mc:\\Users\\Andreu\\anaconda3\\envs\\ml_project_env\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:132\u001b[0m, in \u001b[0;36mBaseWeightBoosting.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    129\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39msample_weight cannot contain negative weights\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    131\u001b[0m \u001b[39m# Check parameters\u001b[39;00m\n\u001b[1;32m--> 132\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_estimator()\n\u001b[0;32m    134\u001b[0m \u001b[39m# Clear any previous fit results\u001b[39;00m\n\u001b[0;32m    135\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_ \u001b[39m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\Andreu\\anaconda3\\envs\\ml_project_env\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:503\u001b[0m, in \u001b[0;36mAdaBoostClassifier._validate_estimator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    495\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[0;32m    496\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mAdaBoostClassifier with algorithm=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mSAMME.R\u001b[39m\u001b[39m'\u001b[39m\u001b[39m requires \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    497\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mthat the weak learner supports the calculation of class \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    500\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39malgorithm=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mSAMME\u001b[39m\u001b[39m'\u001b[39m\u001b[39m instead.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    501\u001b[0m         )\n\u001b[0;32m    502\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m has_fit_parameter(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbase_estimator_, \u001b[39m\"\u001b[39m\u001b[39msample_weight\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m--> 503\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    504\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m doesn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt support sample_weight.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    505\u001b[0m         \u001b[39m%\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbase_estimator_\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\n\u001b[0;32m    506\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: KNeighborsClassifier doesn't support sample_weight."
     ]
    }
   ],
   "source": [
    "ada_knn1 = AdaBoostClassifier(knn_1, n_estimators=100)\n",
    "\n",
    "ada_knn1.fit(X_train_set_scaled, y_train_set)\n",
    "\n",
    "ada_knn1 = ada_knn1.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GradientBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mInit signature:\u001b[0m\n",
      "\u001b[0mGradientBoostingClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;33m*\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'deviance'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0msubsample\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mcriterion\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'friedman_mse'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mmin_samples_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mmin_samples_leaf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mmin_weight_fraction_leaf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mmax_depth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mmin_impurity_decrease\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0minit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mmax_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mmax_leaf_nodes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mwarm_start\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mvalidation_fraction\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mn_iter_no_change\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mtol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0001\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mccp_alpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mSource:\u001b[0m        \n",
      "\u001b[1;32mclass\u001b[0m \u001b[0mGradientBoostingClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mClassifierMixin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBaseGradientBoosting\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;34m\"\"\"Gradient Boosting for classification.\n",
      "\n",
      "    GB builds an additive model in a\n",
      "    forward stage-wise fashion; it allows for the optimization of\n",
      "    arbitrary differentiable loss functions. In each stage ``n_classes_``\n",
      "    regression trees are fit on the negative gradient of the\n",
      "    binomial or multinomial deviance loss function. Binary classification\n",
      "    is a special case where only a single regression tree is induced.\n",
      "\n",
      "    Read more in the :ref:`User Guide <gradient_boosting>`.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    loss : {'deviance', 'exponential'}, default='deviance'\n",
      "        The loss function to be optimized. 'deviance' refers to\n",
      "        deviance (= logistic regression) for classification\n",
      "        with probabilistic outputs. For loss 'exponential' gradient\n",
      "        boosting recovers the AdaBoost algorithm.\n",
      "\n",
      "    learning_rate : float, default=0.1\n",
      "        Learning rate shrinks the contribution of each tree by `learning_rate`.\n",
      "        There is a trade-off between learning_rate and n_estimators.\n",
      "\n",
      "    n_estimators : int, default=100\n",
      "        The number of boosting stages to perform. Gradient boosting\n",
      "        is fairly robust to over-fitting so a large number usually\n",
      "        results in better performance.\n",
      "\n",
      "    subsample : float, default=1.0\n",
      "        The fraction of samples to be used for fitting the individual base\n",
      "        learners. If smaller than 1.0 this results in Stochastic Gradient\n",
      "        Boosting. `subsample` interacts with the parameter `n_estimators`.\n",
      "        Choosing `subsample < 1.0` leads to a reduction of variance\n",
      "        and an increase in bias.\n",
      "\n",
      "    criterion : {'friedman_mse', 'squared_error', 'mse', 'mae'}, \\\n",
      "            default='friedman_mse'\n",
      "        The function to measure the quality of a split. Supported criteria\n",
      "        are 'friedman_mse' for the mean squared error with improvement\n",
      "        score by Friedman, 'squared_error' for mean squared error, and 'mae'\n",
      "        for the mean absolute error. The default value of 'friedman_mse' is\n",
      "        generally the best as it can provide a better approximation in some\n",
      "        cases.\n",
      "\n",
      "        .. versionadded:: 0.18\n",
      "\n",
      "        .. deprecated:: 0.24\n",
      "            `criterion='mae'` is deprecated and will be removed in version\n",
      "            1.1 (renaming of 0.26). Use `criterion='friedman_mse'` or\n",
      "            `'squared_error'` instead, as trees should use a squared error\n",
      "            criterion in Gradient Boosting.\n",
      "\n",
      "        .. deprecated:: 1.0\n",
      "            Criterion 'mse' was deprecated in v1.0 and will be removed in\n",
      "            version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "\n",
      "    min_samples_split : int or float, default=2\n",
      "        The minimum number of samples required to split an internal node:\n",
      "\n",
      "        - If int, then consider `min_samples_split` as the minimum number.\n",
      "        - If float, then `min_samples_split` is a fraction and\n",
      "          `ceil(min_samples_split * n_samples)` are the minimum\n",
      "          number of samples for each split.\n",
      "\n",
      "        .. versionchanged:: 0.18\n",
      "           Added float values for fractions.\n",
      "\n",
      "    min_samples_leaf : int or float, default=1\n",
      "        The minimum number of samples required to be at a leaf node.\n",
      "        A split point at any depth will only be considered if it leaves at\n",
      "        least ``min_samples_leaf`` training samples in each of the left and\n",
      "        right branches.  This may have the effect of smoothing the model,\n",
      "        especially in regression.\n",
      "\n",
      "        - If int, then consider `min_samples_leaf` as the minimum number.\n",
      "        - If float, then `min_samples_leaf` is a fraction and\n",
      "          `ceil(min_samples_leaf * n_samples)` are the minimum\n",
      "          number of samples for each node.\n",
      "\n",
      "        .. versionchanged:: 0.18\n",
      "           Added float values for fractions.\n",
      "\n",
      "    min_weight_fraction_leaf : float, default=0.0\n",
      "        The minimum weighted fraction of the sum total of weights (of all\n",
      "        the input samples) required to be at a leaf node. Samples have\n",
      "        equal weight when sample_weight is not provided.\n",
      "\n",
      "    max_depth : int, default=3\n",
      "        The maximum depth of the individual regression estimators. The maximum\n",
      "        depth limits the number of nodes in the tree. Tune this parameter\n",
      "        for best performance; the best value depends on the interaction\n",
      "        of the input variables.\n",
      "\n",
      "    min_impurity_decrease : float, default=0.0\n",
      "        A node will be split if this split induces a decrease of the impurity\n",
      "        greater than or equal to this value.\n",
      "\n",
      "        The weighted impurity decrease equation is the following::\n",
      "\n",
      "            N_t / N * (impurity - N_t_R / N_t * right_impurity\n",
      "                                - N_t_L / N_t * left_impurity)\n",
      "\n",
      "        where ``N`` is the total number of samples, ``N_t`` is the number of\n",
      "        samples at the current node, ``N_t_L`` is the number of samples in the\n",
      "        left child, and ``N_t_R`` is the number of samples in the right child.\n",
      "\n",
      "        ``N``, ``N_t``, ``N_t_R`` and ``N_t_L`` all refer to the weighted sum,\n",
      "        if ``sample_weight`` is passed.\n",
      "\n",
      "        .. versionadded:: 0.19\n",
      "\n",
      "    init : estimator or 'zero', default=None\n",
      "        An estimator object that is used to compute the initial predictions.\n",
      "        ``init`` has to provide :meth:`fit` and :meth:`predict_proba`. If\n",
      "        'zero', the initial raw predictions are set to zero. By default, a\n",
      "        ``DummyEstimator`` predicting the classes priors is used.\n",
      "\n",
      "    random_state : int, RandomState instance or None, default=None\n",
      "        Controls the random seed given to each Tree estimator at each\n",
      "        boosting iteration.\n",
      "        In addition, it controls the random permutation of the features at\n",
      "        each split (see Notes for more details).\n",
      "        It also controls the random splitting of the training data to obtain a\n",
      "        validation set if `n_iter_no_change` is not None.\n",
      "        Pass an int for reproducible output across multiple function calls.\n",
      "        See :term:`Glossary <random_state>`.\n",
      "\n",
      "    max_features : {'auto', 'sqrt', 'log2'}, int or float, default=None\n",
      "        The number of features to consider when looking for the best split:\n",
      "\n",
      "        - If int, then consider `max_features` features at each split.\n",
      "        - If float, then `max_features` is a fraction and\n",
      "          `int(max_features * n_features)` features are considered at each\n",
      "          split.\n",
      "        - If 'auto', then `max_features=sqrt(n_features)`.\n",
      "        - If 'sqrt', then `max_features=sqrt(n_features)`.\n",
      "        - If 'log2', then `max_features=log2(n_features)`.\n",
      "        - If None, then `max_features=n_features`.\n",
      "\n",
      "        Choosing `max_features < n_features` leads to a reduction of variance\n",
      "        and an increase in bias.\n",
      "\n",
      "        Note: the search for a split does not stop until at least one\n",
      "        valid partition of the node samples is found, even if it requires to\n",
      "        effectively inspect more than ``max_features`` features.\n",
      "\n",
      "    verbose : int, default=0\n",
      "        Enable verbose output. If 1 then it prints progress and performance\n",
      "        once in a while (the more trees the lower the frequency). If greater\n",
      "        than 1 then it prints progress and performance for every tree.\n",
      "\n",
      "    max_leaf_nodes : int, default=None\n",
      "        Grow trees with ``max_leaf_nodes`` in best-first fashion.\n",
      "        Best nodes are defined as relative reduction in impurity.\n",
      "        If None then unlimited number of leaf nodes.\n",
      "\n",
      "    warm_start : bool, default=False\n",
      "        When set to ``True``, reuse the solution of the previous call to fit\n",
      "        and add more estimators to the ensemble, otherwise, just erase the\n",
      "        previous solution. See :term:`the Glossary <warm_start>`.\n",
      "\n",
      "    validation_fraction : float, default=0.1\n",
      "        The proportion of training data to set aside as validation set for\n",
      "        early stopping. Must be between 0 and 1.\n",
      "        Only used if ``n_iter_no_change`` is set to an integer.\n",
      "\n",
      "        .. versionadded:: 0.20\n",
      "\n",
      "    n_iter_no_change : int, default=None\n",
      "        ``n_iter_no_change`` is used to decide if early stopping will be used\n",
      "        to terminate training when validation score is not improving. By\n",
      "        default it is set to None to disable early stopping. If set to a\n",
      "        number, it will set aside ``validation_fraction`` size of the training\n",
      "        data as validation and terminate training when validation score is not\n",
      "        improving in all of the previous ``n_iter_no_change`` numbers of\n",
      "        iterations. The split is stratified.\n",
      "\n",
      "        .. versionadded:: 0.20\n",
      "\n",
      "    tol : float, default=1e-4\n",
      "        Tolerance for the early stopping. When the loss is not improving\n",
      "        by at least tol for ``n_iter_no_change`` iterations (if set to a\n",
      "        number), the training stops.\n",
      "\n",
      "        .. versionadded:: 0.20\n",
      "\n",
      "    ccp_alpha : non-negative float, default=0.0\n",
      "        Complexity parameter used for Minimal Cost-Complexity Pruning. The\n",
      "        subtree with the largest cost complexity that is smaller than\n",
      "        ``ccp_alpha`` will be chosen. By default, no pruning is performed. See\n",
      "        :ref:`minimal_cost_complexity_pruning` for details.\n",
      "\n",
      "        .. versionadded:: 0.22\n",
      "\n",
      "    Attributes\n",
      "    ----------\n",
      "    n_estimators_ : int\n",
      "        The number of estimators as selected by early stopping (if\n",
      "        ``n_iter_no_change`` is specified). Otherwise it is set to\n",
      "        ``n_estimators``.\n",
      "\n",
      "        .. versionadded:: 0.20\n",
      "\n",
      "    feature_importances_ : ndarray of shape (n_features,)\n",
      "        The impurity-based feature importances.\n",
      "        The higher, the more important the feature.\n",
      "        The importance of a feature is computed as the (normalized)\n",
      "        total reduction of the criterion brought by that feature.  It is also\n",
      "        known as the Gini importance.\n",
      "\n",
      "        Warning: impurity-based feature importances can be misleading for\n",
      "        high cardinality features (many unique values). See\n",
      "        :func:`sklearn.inspection.permutation_importance` as an alternative.\n",
      "\n",
      "    oob_improvement_ : ndarray of shape (n_estimators,)\n",
      "        The improvement in loss (= deviance) on the out-of-bag samples\n",
      "        relative to the previous iteration.\n",
      "        ``oob_improvement_[0]`` is the improvement in\n",
      "        loss of the first stage over the ``init`` estimator.\n",
      "        Only available if ``subsample < 1.0``\n",
      "\n",
      "    train_score_ : ndarray of shape (n_estimators,)\n",
      "        The i-th score ``train_score_[i]`` is the deviance (= loss) of the\n",
      "        model at iteration ``i`` on the in-bag sample.\n",
      "        If ``subsample == 1`` this is the deviance on the training data.\n",
      "\n",
      "    loss_ : LossFunction\n",
      "        The concrete ``LossFunction`` object.\n",
      "\n",
      "    init_ : estimator\n",
      "        The estimator that provides the initial predictions.\n",
      "        Set via the ``init`` argument or ``loss.init_estimator``.\n",
      "\n",
      "    estimators_ : ndarray of DecisionTreeRegressor of \\\n",
      "            shape (n_estimators, ``loss_.K``)\n",
      "        The collection of fitted sub-estimators. ``loss_.K`` is 1 for binary\n",
      "        classification, otherwise n_classes.\n",
      "\n",
      "    classes_ : ndarray of shape (n_classes,)\n",
      "        The classes labels.\n",
      "\n",
      "    n_features_ : int\n",
      "        The number of data features.\n",
      "\n",
      "        .. deprecated:: 1.0\n",
      "            Attribute `n_features_` was deprecated in version 1.0 and will be\n",
      "            removed in 1.2. Use `n_features_in_` instead.\n",
      "\n",
      "    n_features_in_ : int\n",
      "        Number of features seen during :term:`fit`.\n",
      "\n",
      "        .. versionadded:: 0.24\n",
      "\n",
      "    feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
      "        Names of features seen during :term:`fit`. Defined only when `X`\n",
      "        has feature names that are all strings.\n",
      "\n",
      "        .. versionadded:: 1.0\n",
      "\n",
      "    n_classes_ : int\n",
      "        The number of classes.\n",
      "\n",
      "    max_features_ : int\n",
      "        The inferred value of max_features.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    HistGradientBoostingClassifier : Histogram-based Gradient Boosting\n",
      "        Classification Tree.\n",
      "    sklearn.tree.DecisionTreeClassifier : A decision tree classifier.\n",
      "    RandomForestClassifier : A meta-estimator that fits a number of decision\n",
      "        tree classifiers on various sub-samples of the dataset and uses\n",
      "        averaging to improve the predictive accuracy and control over-fitting.\n",
      "    AdaBoostClassifier : A meta-estimator that begins by fitting a classifier\n",
      "        on the original dataset and then fits additional copies of the\n",
      "        classifier on the same dataset where the weights of incorrectly\n",
      "        classified instances are adjusted such that subsequent classifiers\n",
      "        focus more on difficult cases.\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    The features are always randomly permuted at each split. Therefore,\n",
      "    the best found split may vary, even with the same training data and\n",
      "    ``max_features=n_features``, if the improvement of the criterion is\n",
      "    identical for several splits enumerated during the search of the best\n",
      "    split. To obtain a deterministic behaviour during fitting,\n",
      "    ``random_state`` has to be fixed.\n",
      "\n",
      "    References\n",
      "    ----------\n",
      "    J. Friedman, Greedy Function Approximation: A Gradient Boosting\n",
      "    Machine, The Annals of Statistics, Vol. 29, No. 5, 2001.\n",
      "\n",
      "    J. Friedman, Stochastic Gradient Boosting, 1999\n",
      "\n",
      "    T. Hastie, R. Tibshirani and J. Friedman.\n",
      "    Elements of Statistical Learning Ed. 2, Springer, 2009.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    The following example shows how to fit a gradient boosting classifier with\n",
      "    100 decision stumps as weak learners.\n",
      "\n",
      "    >>> from sklearn.datasets import make_hastie_10_2\n",
      "    >>> from sklearn.ensemble import GradientBoostingClassifier\n",
      "\n",
      "    >>> X, y = make_hastie_10_2(random_state=0)\n",
      "    >>> X_train, X_test = X[:2000], X[2000:]\n",
      "    >>> y_train, y_test = y[:2000], y[2000:]\n",
      "\n",
      "    >>> clf = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0,\n",
      "    ...     max_depth=1, random_state=0).fit(X_train, y_train)\n",
      "    >>> clf.score(X_test, y_test)\n",
      "    0.913...\n",
      "    \"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0m_SUPPORTED_LOSS\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"deviance\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"exponential\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;33m*\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"deviance\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0msubsample\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mcriterion\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"friedman_mse\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mmin_samples_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mmin_samples_leaf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mmin_weight_fraction_leaf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mmax_depth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mmin_impurity_decrease\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0minit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mmax_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mmax_leaf_nodes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mwarm_start\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mvalidation_fraction\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mn_iter_no_change\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mtol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1e-4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mccp_alpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mcriterion\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mmin_samples_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmin_samples_split\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mmin_samples_leaf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmin_samples_leaf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mmin_weight_fraction_leaf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmin_weight_fraction_leaf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mmax_depth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0minit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minit\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0msubsample\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msubsample\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mmax_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_features\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mmax_leaf_nodes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_leaf_nodes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mmin_impurity_decrease\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmin_impurity_decrease\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mwarm_start\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mwarm_start\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mvalidation_fraction\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_fraction\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mn_iter_no_change\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_iter_no_change\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mtol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtol\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mccp_alpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mccp_alpha\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0m_validate_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mcheck_classification_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_inverse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mn_trim_classes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcount_nonzero\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbincount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0mn_trim_classes\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[1;34m\"y contains %d class after sample_weight \"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[1;34m\"trimmed classes with zero weights, while a \"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[1;34m\"minimum of 2 classes are required.\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mn_trim_classes\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_classes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;31m# expose n_classes_ attribute\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_classes_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_classes\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0m_warn_mae_for_criterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;31m# TODO: This should raise an error from 1.1\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;34m\"criterion='mae' was deprecated in version 0.24 and \"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;34m\"will be removed in version 1.1 (renaming of 0.26). Use \"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;34m\"criterion='friedman_mse' or 'squared_error' instead, as\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;34m\" trees should use a squared error criterion in Gradient\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;34m\" Boosting.\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mFutureWarning\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0mdecision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;34m\"\"\"Compute the decision function of ``X``.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      "            The input samples. Internally, it will be converted to\n",
      "            ``dtype=np.float32`` and if a sparse matrix is provided\n",
      "            to a sparse ``csr_matrix``.\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        score : ndarray of shape (n_samples, n_classes) or (n_samples,)\n",
      "            The decision function of the input samples, which corresponds to\n",
      "            the raw values predicted from the trees of the ensemble . The\n",
      "            order of the classes corresponds to that in the attribute\n",
      "            :term:`classes_`. Regression and binary classification produce an\n",
      "            array of shape (n_samples,).\n",
      "        \"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"C\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"csr\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mraw_predictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_raw_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0mraw_predictions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;32mreturn\u001b[0m \u001b[0mraw_predictions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mreturn\u001b[0m \u001b[0mraw_predictions\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0mstaged_decision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;34m\"\"\"Compute decision function of ``X`` for each iteration.\n",
      "\n",
      "        This method allows monitoring (i.e. determine error on testing set)\n",
      "        after each stage.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      "            The input samples. Internally, it will be converted to\n",
      "            ``dtype=np.float32`` and if a sparse matrix is provided\n",
      "            to a sparse ``csr_matrix``.\n",
      "\n",
      "        Yields\n",
      "        ------\n",
      "        score : generator of ndarray of shape (n_samples, k)\n",
      "            The decision function of the input samples, which corresponds to\n",
      "            the raw values predicted from the trees of the ensemble . The\n",
      "            classes corresponds to that in the attribute :term:`classes_`.\n",
      "            Regression and binary classification are special cases with\n",
      "            ``k == 1``, otherwise ``k==n_classes``.\n",
      "        \"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32myield\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_staged_raw_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;34m\"\"\"Predict class for X.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      "            The input samples. Internally, it will be converted to\n",
      "            ``dtype=np.float32`` and if a sparse matrix is provided\n",
      "            to a sparse ``csr_matrix``.\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        y : ndarray of shape (n_samples,)\n",
      "            The predicted values.\n",
      "        \"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mraw_predictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mencoded_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_raw_prediction_to_decision\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_predictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencoded_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0mstaged_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;34m\"\"\"Predict class at each stage for X.\n",
      "\n",
      "        This method allows monitoring (i.e. determine error on testing set)\n",
      "        after each stage.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      "            The input samples. Internally, it will be converted to\n",
      "            ``dtype=np.float32`` and if a sparse matrix is provided\n",
      "            to a sparse ``csr_matrix``.\n",
      "\n",
      "        Yields\n",
      "        -------\n",
      "        y : generator of ndarray of shape (n_samples,)\n",
      "            The predicted value of the input samples.\n",
      "        \"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mfor\u001b[0m \u001b[0mraw_predictions\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_staged_raw_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mencoded_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_raw_prediction_to_decision\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_predictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;32myield\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencoded_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;34m\"\"\"Predict class probabilities for X.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      "            The input samples. Internally, it will be converted to\n",
      "            ``dtype=np.float32`` and if a sparse matrix is provided\n",
      "            to a sparse ``csr_matrix``.\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        p : ndarray of shape (n_samples, n_classes)\n",
      "            The class probabilities of the input samples. The order of the\n",
      "            classes corresponds to that in the attribute :term:`classes_`.\n",
      "\n",
      "        Raises\n",
      "        ------\n",
      "        AttributeError\n",
      "            If the ``loss`` does not support probabilities.\n",
      "        \"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mraw_predictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_raw_prediction_to_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_predictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mexcept\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;32mraise\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[1;34m\"loss=%r does not support predict_proba\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0mpredict_log_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;34m\"\"\"Predict class log-probabilities for X.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      "            The input samples. Internally, it will be converted to\n",
      "            ``dtype=np.float32`` and if a sparse matrix is provided\n",
      "            to a sparse ``csr_matrix``.\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        p : ndarray of shape (n_samples, n_classes)\n",
      "            The class log-probabilities of the input samples. The order of the\n",
      "            classes corresponds to that in the attribute :term:`classes_`.\n",
      "\n",
      "        Raises\n",
      "        ------\n",
      "        AttributeError\n",
      "            If the ``loss`` does not support probabilities.\n",
      "        \"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mproba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mproba\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0mstaged_predict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;34m\"\"\"Predict class probabilities at each stage for X.\n",
      "\n",
      "        This method allows monitoring (i.e. determine error on testing set)\n",
      "        after each stage.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      "            The input samples. Internally, it will be converted to\n",
      "            ``dtype=np.float32`` and if a sparse matrix is provided\n",
      "            to a sparse ``csr_matrix``.\n",
      "\n",
      "        Yields\n",
      "        ------\n",
      "        y : generator of ndarray of shape (n_samples,)\n",
      "            The predicted value of the input samples.\n",
      "        \"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;32mfor\u001b[0m \u001b[0mraw_predictions\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_staged_raw_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[1;32myield\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_raw_prediction_to_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_predictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mexcept\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;32mraise\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[1;34m\"loss=%r does not support predict_proba\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFile:\u001b[0m           c:\\users\\andreu\\anaconda3\\envs\\ml_project_env\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\n",
      "\u001b[1;31mType:\u001b[0m           ABCMeta\n",
      "\u001b[1;31mSubclasses:\u001b[0m     \n"
     ]
    }
   ],
   "source": [
    "GradientBoostingClassifier??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = GradientBoostingClassifier(n_estimators=100)\n",
    "gb.fit(X_train_set_scaled, y_train_set)\n",
    "\n",
    "gb_preds = gb.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7908   20]\n",
      " [ 244   53]]\n",
      "Recall: 0.17845117845117844\n",
      "f1_score: 0.2864864864864865\n",
      "roc_auc: 0.5879642370560635\n"
     ]
    }
   ],
   "source": [
    "evaluate(y_test, gb_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, feature_types=None, gamma=0, gpu_id=-1,\n",
       "              grow_policy='depthwise', importance_type=None,\n",
       "              interaction_constraints='', learning_rate=0.300000012,\n",
       "              max_bin=256, max_cat_threshold=64, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints='()', n_estimators=100,\n",
       "              n_jobs=0, num_parallel_tree=1, predictor='auto', random_state=0, ...)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb = XGBClassifier()\n",
    "xgb.fit(X_train_set_scaled, y_train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_preds = xgb.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7903   25]\n",
      " [ 204   93]]\n",
      "Recall: 0.31313131313131315\n",
      "f1_score: 0.4481927710843373\n",
      "roc_auc: 0.6549889663537495\n"
     ]
    }
   ],
   "source": [
    "evaluate(y_test, xgb_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb2 = XGBClassifier(n_estimators=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, feature_types=None, gamma=0, gpu_id=-1,\n",
       "              grow_policy='depthwise', importance_type=None,\n",
       "              interaction_constraints='', learning_rate=0.300000012,\n",
       "              max_bin=256, max_cat_threshold=64, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints='()', n_estimators=200,\n",
       "              n_jobs=0, num_parallel_tree=1, predictor='auto', random_state=0, ...)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb2.fit(X_train_set_scaled, y_train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb2_preds = xgb2.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7895   33]\n",
      " [ 203   94]]\n",
      "Recall: 0.3164983164983165\n",
      "f1_score: 0.4433962264150943\n",
      "roc_auc: 0.6561679271694408\n"
     ]
    }
   ],
   "source": [
    "evaluate(y_test, xgb2_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRFClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mInit signature:\u001b[0m\n",
      "\u001b[0mXGBClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;33m*\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mobjective\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCallable\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTuple\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'binary:logistic'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0muse_label_encoder\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mDocstring:\u001b[0m     \n",
      "Implementation of the scikit-learn API for XGBoost classification.\n",
      "\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "\n",
      "    n_estimators : int\n",
      "        Number of boosting rounds.\n",
      "\n",
      "    max_depth :  Optional[int]\n",
      "        Maximum tree depth for base learners.\n",
      "    max_leaves :\n",
      "        Maximum number of leaves; 0 indicates no limit.\n",
      "    max_bin :\n",
      "        If using histogram-based algorithm, maximum number of bins per feature\n",
      "    grow_policy :\n",
      "        Tree growing policy. 0: favor splitting at nodes closest to the node, i.e. grow\n",
      "        depth-wise. 1: favor splitting at nodes with highest loss change.\n",
      "    learning_rate : Optional[float]\n",
      "        Boosting learning rate (xgb's \"eta\")\n",
      "    verbosity : Optional[int]\n",
      "        The degree of verbosity. Valid values are 0 (silent) - 3 (debug).\n",
      "    objective : typing.Union[str, typing.Callable[[numpy.ndarray, numpy.ndarray], typing.Tuple[numpy.ndarray, numpy.ndarray]], NoneType]\n",
      "        Specify the learning task and the corresponding learning objective or\n",
      "        a custom objective function to be used (see note below).\n",
      "    booster: Optional[str]\n",
      "        Specify which booster to use: gbtree, gblinear or dart.\n",
      "    tree_method: Optional[str]\n",
      "        Specify which tree method to use.  Default to auto.  If this parameter is set to\n",
      "        default, XGBoost will choose the most conservative option available.  It's\n",
      "        recommended to study this option from the parameters document :doc:`tree method\n",
      "        </treemethod>`\n",
      "    n_jobs : Optional[int]\n",
      "        Number of parallel threads used to run xgboost.  When used with other\n",
      "        Scikit-Learn algorithms like grid search, you may choose which algorithm to\n",
      "        parallelize and balance the threads.  Creating thread contention will\n",
      "        significantly slow down both algorithms.\n",
      "    gamma : Optional[float]\n",
      "        (min_split_loss) Minimum loss reduction required to make a further partition on a\n",
      "        leaf node of the tree.\n",
      "    min_child_weight : Optional[float]\n",
      "        Minimum sum of instance weight(hessian) needed in a child.\n",
      "    max_delta_step : Optional[float]\n",
      "        Maximum delta step we allow each tree's weight estimation to be.\n",
      "    subsample : Optional[float]\n",
      "        Subsample ratio of the training instance.\n",
      "    sampling_method :\n",
      "        Sampling method. Used only by `gpu_hist` tree method.\n",
      "          - `uniform`: select random training instances uniformly.\n",
      "          - `gradient_based` select random training instances with higher probability when\n",
      "            the gradient and hessian are larger. (cf. CatBoost)\n",
      "    colsample_bytree : Optional[float]\n",
      "        Subsample ratio of columns when constructing each tree.\n",
      "    colsample_bylevel : Optional[float]\n",
      "        Subsample ratio of columns for each level.\n",
      "    colsample_bynode : Optional[float]\n",
      "        Subsample ratio of columns for each split.\n",
      "    reg_alpha : Optional[float]\n",
      "        L1 regularization term on weights (xgb's alpha).\n",
      "    reg_lambda : Optional[float]\n",
      "        L2 regularization term on weights (xgb's lambda).\n",
      "    scale_pos_weight : Optional[float]\n",
      "        Balancing of positive and negative weights.\n",
      "    base_score : Optional[float]\n",
      "        The initial prediction score of all instances, global bias.\n",
      "    random_state : Optional[Union[numpy.random.RandomState, int]]\n",
      "        Random number seed.\n",
      "\n",
      "        .. note::\n",
      "\n",
      "           Using gblinear booster with shotgun updater is nondeterministic as\n",
      "           it uses Hogwild algorithm.\n",
      "\n",
      "    missing : float, default np.nan\n",
      "        Value in the data which needs to be present as a missing value.\n",
      "    num_parallel_tree: Optional[int]\n",
      "        Used for boosting random forest.\n",
      "    monotone_constraints : Optional[Union[Dict[str, int], str]]\n",
      "        Constraint of variable monotonicity.  See :doc:`tutorial </tutorials/monotonic>`\n",
      "        for more information.\n",
      "    interaction_constraints : Optional[Union[str, List[Tuple[str]]]]\n",
      "        Constraints for interaction representing permitted interactions.  The\n",
      "        constraints must be specified in the form of a nested list, e.g. ``[[0, 1], [2,\n",
      "        3, 4]]``, where each inner list is a group of indices of features that are\n",
      "        allowed to interact with each other.  See :doc:`tutorial\n",
      "        </tutorials/feature_interaction_constraint>` for more information\n",
      "    importance_type: Optional[str]\n",
      "        The feature importance type for the feature_importances\\_ property:\n",
      "\n",
      "        * For tree model, it's either \"gain\", \"weight\", \"cover\", \"total_gain\" or\n",
      "          \"total_cover\".\n",
      "        * For linear model, only \"weight\" is defined and it's the normalized coefficients\n",
      "          without bias.\n",
      "\n",
      "    gpu_id : Optional[int]\n",
      "        Device ordinal.\n",
      "    validate_parameters : Optional[bool]\n",
      "        Give warnings for unknown parameter.\n",
      "    predictor : Optional[str]\n",
      "        Force XGBoost to use specific predictor, available choices are [cpu_predictor,\n",
      "        gpu_predictor].\n",
      "    enable_categorical : bool\n",
      "\n",
      "        .. versionadded:: 1.5.0\n",
      "\n",
      "        .. note:: This parameter is experimental\n",
      "\n",
      "        Experimental support for categorical data.  When enabled, cudf/pandas.DataFrame\n",
      "        should be used to specify categorical data type.  Also, JSON/UBJSON\n",
      "        serialization format is required.\n",
      "\n",
      "    feature_types : FeatureTypes\n",
      "\n",
      "        .. versionadded:: 1.7.0\n",
      "\n",
      "        Used for specifying feature types without constructing a dataframe. See\n",
      "        :py:class:`DMatrix` for details.\n",
      "\n",
      "    max_cat_to_onehot : Optional[int]\n",
      "\n",
      "        .. versionadded:: 1.6.0\n",
      "\n",
      "        .. note:: This parameter is experimental\n",
      "\n",
      "        A threshold for deciding whether XGBoost should use one-hot encoding based split\n",
      "        for categorical data.  When number of categories is lesser than the threshold\n",
      "        then one-hot encoding is chosen, otherwise the categories will be partitioned\n",
      "        into children nodes. Also, `enable_categorical` needs to be set to have\n",
      "        categorical feature support. See :doc:`Categorical Data\n",
      "        </tutorials/categorical>` and :ref:`cat-param` for details.\n",
      "\n",
      "    max_cat_threshold : Optional[int]\n",
      "\n",
      "        .. versionadded:: 1.7.0\n",
      "\n",
      "        .. note:: This parameter is experimental\n",
      "\n",
      "        Maximum number of categories considered for each split. Used only by\n",
      "        partition-based splits for preventing over-fitting. Also, `enable_categorical`\n",
      "        needs to be set to have categorical feature support. See :doc:`Categorical Data\n",
      "        </tutorials/categorical>` and :ref:`cat-param` for details.\n",
      "\n",
      "    eval_metric : Optional[Union[str, List[str], Callable]]\n",
      "\n",
      "        .. versionadded:: 1.6.0\n",
      "\n",
      "        Metric used for monitoring the training result and early stopping.  It can be a\n",
      "        string or list of strings as names of predefined metric in XGBoost (See\n",
      "        doc/parameter.rst), one of the metrics in :py:mod:`sklearn.metrics`, or any other\n",
      "        user defined metric that looks like `sklearn.metrics`.\n",
      "\n",
      "        If custom objective is also provided, then custom metric should implement the\n",
      "        corresponding reverse link function.\n",
      "\n",
      "        Unlike the `scoring` parameter commonly used in scikit-learn, when a callable\n",
      "        object is provided, it's assumed to be a cost function and by default XGBoost will\n",
      "        minimize the result during early stopping.\n",
      "\n",
      "        For advanced usage on Early stopping like directly choosing to maximize instead of\n",
      "        minimize, see :py:obj:`xgboost.callback.EarlyStopping`.\n",
      "\n",
      "        See :doc:`Custom Objective and Evaluation Metric </tutorials/custom_metric_obj>`\n",
      "        for more.\n",
      "\n",
      "        .. note::\n",
      "\n",
      "             This parameter replaces `eval_metric` in :py:meth:`fit` method.  The old one\n",
      "             receives un-transformed prediction regardless of whether custom objective is\n",
      "             being used.\n",
      "\n",
      "        .. code-block:: python\n",
      "\n",
      "            from sklearn.datasets import load_diabetes\n",
      "            from sklearn.metrics import mean_absolute_error\n",
      "            X, y = load_diabetes(return_X_y=True)\n",
      "            reg = xgb.XGBRegressor(\n",
      "                tree_method=\"hist\",\n",
      "                eval_metric=mean_absolute_error,\n",
      "            )\n",
      "            reg.fit(X, y, eval_set=[(X, y)])\n",
      "\n",
      "    early_stopping_rounds : Optional[int]\n",
      "\n",
      "        .. versionadded:: 1.6.0\n",
      "\n",
      "        Activates early stopping. Validation metric needs to improve at least once in\n",
      "        every **early_stopping_rounds** round(s) to continue training.  Requires at least\n",
      "        one item in **eval_set** in :py:meth:`fit`.\n",
      "\n",
      "        The method returns the model from the last iteration (not the best one).  If\n",
      "        there's more than one item in **eval_set**, the last entry will be used for early\n",
      "        stopping.  If there's more than one metric in **eval_metric**, the last metric\n",
      "        will be used for early stopping.\n",
      "\n",
      "        If early stopping occurs, the model will have three additional fields:\n",
      "        :py:attr:`best_score`, :py:attr:`best_iteration` and\n",
      "        :py:attr:`best_ntree_limit`.\n",
      "\n",
      "        .. note::\n",
      "\n",
      "            This parameter replaces `early_stopping_rounds` in :py:meth:`fit` method.\n",
      "\n",
      "    callbacks : Optional[List[TrainingCallback]]\n",
      "        List of callback functions that are applied at end of each iteration.\n",
      "        It is possible to use predefined callbacks by using\n",
      "        :ref:`Callback API <callback_api>`.\n",
      "\n",
      "        .. note::\n",
      "\n",
      "           States in callback are not preserved during training, which means callback\n",
      "           objects can not be reused for multiple training sessions without\n",
      "           reinitialization or deepcopy.\n",
      "\n",
      "        .. code-block:: python\n",
      "\n",
      "            for params in parameters_grid:\n",
      "                # be sure to (re)initialize the callbacks before each run\n",
      "                callbacks = [xgb.callback.LearningRateScheduler(custom_rates)]\n",
      "                xgboost.train(params, Xy, callbacks=callbacks)\n",
      "\n",
      "    kwargs : dict, optional\n",
      "        Keyword arguments for XGBoost Booster object.  Full documentation of parameters\n",
      "        can be found :doc:`here </parameter>`.\n",
      "        Attempting to set a parameter via the constructor args and \\*\\*kwargs\n",
      "        dict simultaneously will result in a TypeError.\n",
      "\n",
      "        .. note:: \\*\\*kwargs unsupported by scikit-learn\n",
      "\n",
      "            \\*\\*kwargs is unsupported by scikit-learn.  We do not guarantee\n",
      "            that parameters passed via this argument will interact properly\n",
      "            with scikit-learn.\n",
      "\n",
      "        .. note::  Custom objective function\n",
      "\n",
      "            A custom objective function can be provided for the ``objective``\n",
      "            parameter. In this case, it should have the signature\n",
      "            ``objective(y_true, y_pred) -> grad, hess``:\n",
      "\n",
      "            y_true: array_like of shape [n_samples]\n",
      "                The target values\n",
      "            y_pred: array_like of shape [n_samples]\n",
      "                The predicted values\n",
      "\n",
      "            grad: array_like of shape [n_samples]\n",
      "                The value of the gradient for each sample point.\n",
      "            hess: array_like of shape [n_samples]\n",
      "                The value of the second derivative for each sample point\n",
      "\u001b[1;31mSource:\u001b[0m        \n",
      "\u001b[1;33m@\u001b[0m\u001b[0mxgboost_model_doc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;34m\"Implementation of the scikit-learn API for XGBoost classification.\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;33m[\u001b[0m\u001b[1;34m\"model\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"objective\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mextra_parameters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\"\"\n",
      "    n_estimators : int\n",
      "        Number of boosting rounds.\n",
      "\"\"\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;32mclass\u001b[0m \u001b[0mXGBClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXGBModel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mXGBClassifierBase\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;31m# pylint: disable=missing-docstring,invalid-name,too-many-instance-attributes\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;33m@\u001b[0m\u001b[0m_deprecate_positional_args\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;33m*\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mobjective\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0m_SklObjective\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"binary:logistic\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0muse_label_encoder\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;31m# must match the parameters for `get_params`\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse_label_encoder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0muse_label_encoder\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0muse_label_encoder\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Label encoder was removed in 1.6.0.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0muse_label_encoder\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"`use_label_encoder` is deprecated in 1.7.0.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobjective\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;33m@\u001b[0m\u001b[0m_deprecate_positional_args\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mArrayLike\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mArrayLike\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;33m*\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0msample_weight\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mArrayLike\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mbase_margin\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mArrayLike\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0meval_set\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mSequence\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mTuple\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mArrayLike\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mArrayLike\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0meval_metric\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSequence\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMetric\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mearly_stopping_rounds\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mverbose\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mxgb_model\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mBooster\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mXGBModel\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0msample_weight_eval_set\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mSequence\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mArrayLike\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mbase_margin_eval_set\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mSequence\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mArrayLike\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mfeature_weights\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mArrayLike\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mcallbacks\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mSequence\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mTrainingCallback\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;34m\"XGBClassifier\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;31m# pylint: disable = attribute-defined-outside-init,too-many-statements\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mverbosity\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbosity\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mevals_result\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTrainingCallback\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEvalsLog\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;32mif\u001b[0m \u001b[0m_is_cudf_df\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0m_is_cudf_ser\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[1;32mimport\u001b[0m \u001b[0mcupy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcp\u001b[0m  \u001b[1;31m# pylint: disable=E0401\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_classes_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mexpected_classes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_classes_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;32melif\u001b[0m \u001b[0m_is_cupy_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[1;32mimport\u001b[0m \u001b[0mcupy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcp\u001b[0m  \u001b[1;31m# pylint: disable=E0401\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_classes_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mexpected_classes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_classes_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_classes_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mexpected_classes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_classes_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mexpected_classes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[1;32mor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mexpected_classes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                    \u001b[1;34mf\"Invalid classes inferred from unique values of `y`.  \"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                    \u001b[1;34mf\"Expected: {expected_classes}, got {self.classes_}\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_xgb_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobjective\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mobj\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                    \u001b[0mCallable\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDMatrix\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTuple\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_objective_decorator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobjective\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[1;31m# Use default value. Is it really not used ?\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"objective\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"binary:logistic\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_classes_\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[1;31m# Switch to using a multiclass objective in the underlying XGB instance\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[1;32mif\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"objective\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"multi:softmax\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                    \u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"objective\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"multi:softprob\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"num_class\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_classes_\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mmetric\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mearly_stopping_rounds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_configure_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mxgb_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meval_metric\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mearly_stopping_rounds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mtrain_dmatrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevals\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_wrap_evaluation_matrices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mmissing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mgroup\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mqid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mbase_margin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbase_margin\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mfeature_weights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeature_weights\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0meval_set\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0meval_set\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0msample_weight_eval_set\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight_eval_set\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mbase_margin_eval_set\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbase_margin_eval_set\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0meval_group\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0meval_qid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mcreate_dmatrix\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_dmatrix\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0menable_categorical\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable_categorical\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mfeature_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_types\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_Booster\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mtrain_dmatrix\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_num_boosting_rounds\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mevals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mearly_stopping_rounds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mearly_stopping_rounds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mevals_result\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mcustom_metric\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmetric\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mverbose_eval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mxgb_model\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobjective\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobjective\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"objective\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_evaluation_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32massert\u001b[0m \u001b[0mXGBModel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mfit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mXGBModel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;34m\"Fit gradient boosting model\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Fit gradient boosting classifier\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mArrayLike\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0moutput_margin\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mntree_limit\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mvalidate_features\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mbase_margin\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mArrayLike\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0miteration_range\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mTuple\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mverbosity\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbosity\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mclass_probs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0moutput_margin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_margin\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mntree_limit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mntree_limit\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mvalidate_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidate_features\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mbase_margin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbase_margin\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0miteration_range\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0miteration_range\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;32mif\u001b[0m \u001b[0moutput_margin\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[1;31m# If output_margin is active, simply return the scores\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[1;32mreturn\u001b[0m \u001b[0mclass_probs\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclass_probs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_classes_\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[1;31m# multi-class, turns softprob into softmax\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mcolumn_indexes\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclass_probs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclass_probs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mclass_probs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[1;31m# multi-label\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mcolumn_indexes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclass_probs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mcolumn_indexes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mclass_probs\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobjective\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"multi:softmax\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[1;32mreturn\u001b[0m \u001b[0mclass_probs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[1;31m# turns soft logit into class label\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mcolumn_indexes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_probs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mcolumn_indexes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mclass_probs\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"_le\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_le\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumn_indexes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;32mreturn\u001b[0m \u001b[0mcolumn_indexes\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mArrayLike\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mntree_limit\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mvalidate_features\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mbase_margin\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mArrayLike\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0miteration_range\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mTuple\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;34m\"\"\"Predict the probability of each `X` example being of a given class.\n",
      "\n",
      "        .. note:: This function is only thread safe for `gbtree` and `dart`.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        X : array_like\n",
      "            Feature matrix.\n",
      "        ntree_limit : int\n",
      "            Deprecated, use `iteration_range` instead.\n",
      "        validate_features : bool\n",
      "            When this is True, validate that the Booster's and data's feature_names are\n",
      "            identical.  Otherwise, it is assumed that the feature_names are the same.\n",
      "        base_margin : array_like\n",
      "            Margin added to prediction.\n",
      "        iteration_range :\n",
      "            Specifies which layer of trees are used in prediction.  For example, if a\n",
      "            random forest is trained with 100 rounds.  Specifying `iteration_range=(10,\n",
      "            20)`, then only the forests built during [10, 20) (half open set) rounds are\n",
      "            used in this prediction.\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        prediction :\n",
      "            a numpy array of shape array-like of shape (n_samples, n_classes) with the\n",
      "            probability of each data example being of a given class.\n",
      "        \"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;31m# custom obj:      Do nothing as we don't know what to do.\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;31m# softprob:        Do nothing, output is proba.\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;31m# softmax:         Use softmax from scipy\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;31m# binary:logistic: Expand the prob vector into 2-class matrix after predict.\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;31m# binary:logitraw: Unsupported by predict_proba()\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobjective\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"multi:softmax\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mraw_predt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mntree_limit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mntree_limit\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mvalidate_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidate_features\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0mbase_margin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbase_margin\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0miteration_range\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0miteration_range\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m                \u001b[0moutput_margin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mclass_prob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msoftmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_predt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;32mreturn\u001b[0m \u001b[0mclass_prob\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[0mclass_probs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mntree_limit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mntree_limit\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mvalidate_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidate_features\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mbase_margin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbase_margin\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0miteration_range\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0miteration_range\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;31m# If model is loaded from a raw booster there's no `n_classes_`\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mreturn\u001b[0m \u001b[0m_cls_predict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"n_classes_\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_probs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFile:\u001b[0m           c:\\users\\andreu\\anaconda3\\envs\\ml_project_env\\lib\\site-packages\\xgboost\\sklearn.py\n",
      "\u001b[1;31mType:\u001b[0m           type\n",
      "\u001b[1;31mSubclasses:\u001b[0m     XGBRFClassifier\n"
     ]
    }
   ],
   "source": [
    "XGBClassifier??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbrf = XGBRFClassifier(n_estimators=100)\n",
    "\n",
    "xgbrf.fit(X_train_set_scaled, y_train_set)\n",
    "xgbrf_preds = xgbrf.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7915   13]\n",
      " [ 264   33]]\n",
      "Recall: 0.1111111111111111\n",
      "f1_score: 0.1924198250728863\n",
      "roc_auc: 0.5547356766453638\n"
     ]
    }
   ],
   "source": [
    "evaluate(y_test, xgbrf_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [(\"Logistic Regression\",  lg3), (\"Ada\", ada_lg4), (\"knn\", knn_1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_clf = VotingClassifier(estimators=estimators, voting=\"hard\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Andreu\\anaconda3\\envs\\ml_project_env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('Logistic Regression', LogisticRegression()),\n",
       "                             ('Ada',\n",
       "                              AdaBoostClassifier(base_estimator=LogisticRegression(class_weight={0: 1,\n",
       "                                                                                                 1: 5},\n",
       "                                                                                   solver='newton-cg'),\n",
       "                                                 n_estimators=100)),\n",
       "                             ('knn', KNeighborsClassifier(n_neighbors=1))])"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_clf.fit(X_train_set_scaled, y_train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_preds= voting_clf.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7815  113]\n",
      " [ 187  110]]\n",
      "Recall: 0.37037037037037035\n",
      "f1_score: 0.423076923076923\n",
      "roc_auc: 0.6780585454273647\n"
     ]
    }
   ],
   "source": [
    "evaluate(y_test, voting_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_soft = VotingClassifier(estimators=estimators, voting=\"soft\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Andreu\\anaconda3\\envs\\ml_project_env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('Logistic Regression', LogisticRegression()),\n",
       "                             ('Ada',\n",
       "                              AdaBoostClassifier(base_estimator=LogisticRegression(class_weight={0: 1,\n",
       "                                                                                                 1: 5},\n",
       "                                                                                   solver='newton-cg'),\n",
       "                                                 n_estimators=100)),\n",
       "                             ('knn', KNeighborsClassifier(n_neighbors=1))],\n",
       "                 voting='soft')"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_soft.fit(X_train_set_scaled, y_train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_soft_preds= voting_soft.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7808  120]\n",
      " [ 175  122]]\n",
      "Recall: 0.4107744107744108\n",
      "f1_score: 0.45269016697588127\n",
      "roc_auc: 0.697819092370051\n"
     ]
    }
   ],
   "source": [
    "evaluate(y_test, voting_soft_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators2 = [(\"Logistic Regression\",  lg3), (\"xgb\", xgb), (\"Ada\", ada_lg4), (\"knn\", knn_1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_clf_2 = VotingClassifier(estimators=estimators2, voting=\"hard\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Andreu\\anaconda3\\envs\\ml_project_env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('Logistic Regression', LogisticRegression()),\n",
       "                             ('xgb',\n",
       "                              XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                                            callbacks=None, colsample_bylevel=1,\n",
       "                                            colsample_bynode=1,\n",
       "                                            colsample_bytree=1,\n",
       "                                            early_stopping_rounds=None,\n",
       "                                            enable_categorical=False,\n",
       "                                            eval_metric=None,\n",
       "                                            feature_types=None, gamma=0,\n",
       "                                            gpu_id=-1, grow_policy='depthwise',\n",
       "                                            importance_type=None,...\n",
       "                                            max_delta_step=0, max_depth=6,\n",
       "                                            max_leaves=0, min_child_weight=1,\n",
       "                                            missing=nan,\n",
       "                                            monotone_constraints='()',\n",
       "                                            n_estimators=100, n_jobs=0,\n",
       "                                            num_parallel_tree=1,\n",
       "                                            predictor='auto', random_state=0, ...)),\n",
       "                             ('Ada',\n",
       "                              AdaBoostClassifier(base_estimator=LogisticRegression(class_weight={0: 1,\n",
       "                                                                                                 1: 5},\n",
       "                                                                                   solver='newton-cg'),\n",
       "                                                 n_estimators=100)),\n",
       "                             ('knn', KNeighborsClassifier(n_neighbors=1))])"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_clf_2.fit(X_train_set_scaled, y_train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_2_preds= voting_clf_2.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7899   29]\n",
      " [ 203   94]]\n",
      "Recall: 0.3164983164983165\n",
      "f1_score: 0.44761904761904764\n",
      "roc_auc: 0.656420197603346\n"
     ]
    }
   ],
   "source": [
    "evaluate(y_test, voting_2_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_soft_2 = VotingClassifier(estimators=estimators2, voting=\"soft\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Andreu\\anaconda3\\envs\\ml_project_env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('Logistic Regression', LogisticRegression()),\n",
       "                             ('xgb',\n",
       "                              XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                                            callbacks=None, colsample_bylevel=1,\n",
       "                                            colsample_bynode=1,\n",
       "                                            colsample_bytree=1,\n",
       "                                            early_stopping_rounds=None,\n",
       "                                            enable_categorical=False,\n",
       "                                            eval_metric=None,\n",
       "                                            feature_types=None, gamma=0,\n",
       "                                            gpu_id=-1, grow_policy='depthwise',\n",
       "                                            importance_type=None,...\n",
       "                                            max_delta_step=0, max_depth=6,\n",
       "                                            max_leaves=0, min_child_weight=1,\n",
       "                                            missing=nan,\n",
       "                                            monotone_constraints='()',\n",
       "                                            n_estimators=100, n_jobs=0,\n",
       "                                            num_parallel_tree=1,\n",
       "                                            predictor='auto', random_state=0, ...)),\n",
       "                             ('Ada',\n",
       "                              AdaBoostClassifier(base_estimator=LogisticRegression(class_weight={0: 1,\n",
       "                                                                                                 1: 5},\n",
       "                                                                                   solver='newton-cg'),\n",
       "                                                 n_estimators=100)),\n",
       "                             ('knn', KNeighborsClassifier(n_neighbors=1))],\n",
       "                 voting='soft')"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_soft_2.fit(X_train_set_scaled, y_train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_soft2_preds= voting_soft_2.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7883   45]\n",
      " [ 194  103]]\n",
      "Recall: 0.3468013468013468\n",
      "f1_score: 0.4629213483146067\n",
      "roc_auc: 0.6705626310192406\n"
     ]
    }
   ],
   "source": [
    "evaluate(y_test, voting_soft2_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_project_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e93d3666df22a1cbda22f57377795b1f486c59d43300ad07c82331dac21e12fa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
